{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "num_samples = 5\n",
    "state_size = 4\n",
    "num_features = 4\n",
    "num_of_operations = 3\n",
    "batch_size = num_samples\n",
    "max_num_features = 10\n",
    "\n",
    "def add(vec):\n",
    "    return reduce((lambda x, y: x + y),vec)\n",
    "\n",
    "def samples_generator(fn, shape, rng, seed=None):\n",
    "    '''\n",
    "    Generate random samples for the model:\n",
    "    @fn - function to be applied on the input features to get the ouput\n",
    "    @shape - shape of the features matrix (num_samples, num_features)\n",
    "    @rng - range of the input features to be generated within (a,b)\n",
    "    @seed  - generation seed\n",
    "    Outputs a tuple of input and output features matrix\n",
    "    '''\n",
    "    x = (rng[1] - rng[0]) * np.random.random_sample(shape) + rng[0]\n",
    "    y = np.apply_along_axis(fn, 1, x).reshape((-1,1))\n",
    "\n",
    "    #x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    #y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "x,y = samples_generator(add, (num_samples, num_features) , (0, 100))\n",
    "\n",
    "def tf_multiply(inpt):\n",
    "    return tf.reshape( tf.reduce_prod(inpt, axis = 1), [batch_size, -1])\n",
    "\n",
    "def tf_add(inpt):\n",
    "    return  tf.reshape( tf.reduce_sum(inpt, axis = 1), [batch_size, -1])\n",
    "\n",
    "def tf_stall(a):\n",
    "    return a\n",
    "\n",
    "\n",
    "x = tf.Variable(x, dtype=tf.float32)\n",
    "\n",
    "x.initializer.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.49476181e+02   1.19012610e+07   3.84333611e+01   9.29976349e+01\n",
      "    7.14285660e+01   4.66166191e+01]\n",
      " [  1.81322830e+02   4.11986550e+06   4.27255707e+01   5.26204147e+01\n",
      "    4.69276009e+01   3.90492363e+01]\n",
      " [  1.57355591e+02   1.12406631e+04   5.37128487e+01   3.58061447e+01\n",
      "    6.77503128e+01   8.62670392e-02]\n",
      " [  2.58221954e+02   1.65438550e+07   7.43373108e+01   6.39807472e+01\n",
      "    7.07143021e+01   4.91895981e+01]\n",
      " [  2.93363800e+02   2.79430180e+07   8.07342987e+01   7.54765930e+01\n",
      "    7.93957977e+01   5.77571068e+01]]\n"
     ]
    }
   ],
   "source": [
    "add    = tf_add(x)\n",
    "mult   = tf_multiply(x)\n",
    "stall  = tf_stall(x)\n",
    "values = tf.concat([add, mult, stall], 1)\n",
    "print(values.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.13667564e+01   5.42079300e+06   1.14737835e+01   2.77632427e+01\n",
      "    2.13240757e+01   1.39167891e+01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  4.46022301e+01   1.87651862e+06   1.27551670e+01   1.57091446e+01\n",
      "    1.40096283e+01   1.16576452e+01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  3.87067108e+01   5.11990332e+03   1.60352764e+01   1.06894617e+01\n",
      "    2.02259808e+01   2.57539097e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  6.35180626e+01   7.53540400e+06   2.21924438e+01   1.91006260e+01\n",
      "    2.11108418e+01   1.46849184e+01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  7.21623383e+01   1.27275010e+07   2.41021805e+01   2.25325623e+01\n",
      "    2.37025890e+01   1.72426376e+01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "[[ 0.24598242  0.45548055  0.29853708  0.29853708  0.29853708  0.29853708]\n",
      " [ 0.24598242  0.45548055  0.29853708  0.29853708  0.29853708  0.29853708]\n",
      " [ 0.24598242  0.45548055  0.29853708  0.29853708  0.29853708  0.29853708]\n",
      " [ 0.24598242  0.45548055  0.29853708  0.29853708  0.29853708  0.29853708]\n",
      " [ 0.24598242  0.45548055  0.29853708  0.29853708  0.29853708  0.29853708]]\n"
     ]
    }
   ],
   "source": [
    "init_state = tf.Variable(np.zeros([batch_size, state_size]), dtype=tf.float32)\n",
    "argmax_dum = tf.Variable([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],  dtype=tf.int32)\n",
    "W = tf.Variable(np.random.rand(state_size+num_features, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_of_operations),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((num_of_operations)), dtype=tf.float32)\n",
    "\n",
    "dummy_matrix = tf.zeros([batch_size, num_features], tf.float32, name=\"dummy_constant\")\n",
    "\n",
    "init_state.initializer.run()\n",
    "argmax_dum.initializer.run()\n",
    "W.initializer.run()\n",
    "b.initializer.run()\n",
    "W2.initializer.run()\n",
    "b2.initializer.run()\n",
    "#dummy_matrix.initializer.run()\n",
    "\n",
    "current_state = init_state\n",
    "current_input = x\n",
    "      \n",
    "input_and_state_concatenated = tf.concat([current_input, current_state], 1)  # Increasing number of columns\n",
    "next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "current_state = next_state\n",
    "    \n",
    "    #calculate softmax and produce the mask of operations\n",
    "logits  = tf.matmul(next_state, W2) + b2 #Broadcasted addition\n",
    "softmax = tf.nn.softmax(logits)\n",
    "softmax_10000 = tf.nn.softmax(logits)\n",
    "softplus = tf.nn.softplus(logits)\n",
    "softsign = tf.nn.softsign(logits)\n",
    "argmax  = tf.argmax(softmax, 1)\n",
    "\n",
    "#lengths_transposed = tf.expand_dims(argmax, 0)\n",
    "#onehot  = tf.one_hot(argmax, num_of_operations)\n",
    "stall_width = tf.shape(stall)[1] - 1 \n",
    "stall_select = tf.slice(softmax, [0,2], [batch_size,1])\n",
    "multiples = [1, stall_width]\n",
    "stall_mask = tf.tile(stall_select, multiples)\n",
    "mask = tf.concat([softmax, stall_mask], 1)\n",
    "#mask = tf.cast(mask, tf.bool)\n",
    "#apply mask\n",
    "#output = tf.boolean_mask(values,mask)\n",
    "output = values * mask\n",
    "nn_soft = tf.nn.softmax(logits)\n",
    "output_width = tf.shape(output)[1]\n",
    "zeros_slice = tf.slice(dummy_matrix, [0,0], [batch_size, max_num_features - output_width])\n",
    "dum_plus_input = tf.concat([output, zeros_slice], 1)\n",
    "print(dum_plus_input.eval())\n",
    "\n",
    "'''\n",
    "print(x.eval())\n",
    "print(\"stall_select\")\n",
    "print(stall_select.eval())\n",
    "print(\"mask\")\n",
    "print(mask.eval())\n",
    "print(\"logits\")\n",
    "print(logits.eval())\n",
    "print(\"softmax\")\n",
    "print(softmax.eval())\n",
    "print(\"softplus\")\n",
    "print(softplus.eval())\n",
    "print(\"softsign\")\n",
    "print(softsign.eval())\n",
    "print(\"softmax*10000\")\n",
    "print(softmax_10000.eval())\n",
    "print(\"onehot\")\n",
    "print(onehot.eval())\n",
    "'''\n",
    "print(mask.eval())\n",
    "#print(mask.eval())\n",
    "#print(output.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "4\n",
      "[[ 249.47618103]\n",
      " [ 181.3228302 ]\n",
      " [ 157.35559082]\n",
      " [ 258.22195435]\n",
      " [ 293.36380005]]\n",
      "[[  1.19012610e+07]\n",
      " [  4.11986550e+06]\n",
      " [  1.12406631e+04]\n",
      " [  1.65438550e+07]\n",
      " [  2.79430180e+07]]\n",
      "[[  3.84333611e+01   9.29976349e+01   7.14285660e+01   4.66166191e+01]\n",
      " [  4.27255707e+01   5.26204147e+01   4.69276009e+01   3.90492363e+01]\n",
      " [  5.37128487e+01   3.58061447e+01   6.77503128e+01   8.62670392e-02]\n",
      " [  7.43373108e+01   6.39807472e+01   7.07143021e+01   4.91895981e+01]\n",
      " [  8.07342987e+01   7.54765930e+01   7.93957977e+01   5.77571068e+01]]\n",
      "[[ 0.24598242]\n",
      " [ 0.24598242]\n",
      " [ 0.24598242]\n",
      " [ 0.24598242]\n",
      " [ 0.24598242]]\n",
      "[[ 0.45548055]\n",
      " [ 0.45548055]\n",
      " [ 0.45548055]\n",
      " [ 0.45548055]\n",
      " [ 0.45548055]]\n",
      "[[ 0.29853708]\n",
      " [ 0.29853708]\n",
      " [ 0.29853708]\n",
      " [ 0.29853708]\n",
      " [ 0.29853708]]\n",
      "[[ 61.36675644   0.           0.           0.        ]\n",
      " [ 44.60223007   0.           0.           0.        ]\n",
      " [ 38.70671082   0.           0.           0.        ]\n",
      " [ 63.51806259   0.           0.           0.        ]\n",
      " [ 72.16233826   0.           0.           0.        ]]\n",
      "[[  5.42079300e+06   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.87651862e+06   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  5.11990332e+03   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  7.53540400e+06   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.27275010e+07   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "[[  1.14737835e+01   2.77632427e+01   2.13240757e+01   1.39167891e+01]\n",
      " [  1.27551670e+01   1.57091446e+01   1.40096283e+01   1.16576452e+01]\n",
      " [  1.60352764e+01   1.06894617e+01   2.02259808e+01   2.57539097e-02]\n",
      " [  2.21924438e+01   1.91006260e+01   2.11108418e+01   1.46849184e+01]\n",
      " [  2.41021805e+01   2.25325623e+01   2.37025890e+01   1.72426376e+01]]\n",
      "[[  5.42086600e+06   2.77632427e+01   2.13240757e+01   1.39167891e+01]\n",
      " [  1.87657600e+06   1.57091446e+01   1.40096283e+01   1.16576452e+01]\n",
      " [  5.17464502e+03   1.06894617e+01   2.02259808e+01   2.57539097e-02]\n",
      " [  7.53548950e+06   1.91006260e+01   2.11108418e+01   1.46849184e+01]\n",
      " [  1.27275970e+07   2.25325623e+01   2.37025890e+01   1.72426376e+01]]\n"
     ]
    }
   ],
   "source": [
    "add_softmax   = tf.slice(softmax, [0,0], [batch_size,1])\n",
    "mult_softmax  = tf.slice(softmax, [0,1], [batch_size,1])\n",
    "stall_softmax = tf.slice(softmax, [0,2], [batch_size,1])\n",
    "\n",
    "add_width   = tf.shape(add)[1]\n",
    "mult_width  = tf.shape(mult)[1]\n",
    "stall_width = tf.shape(stall)[1]\n",
    "\n",
    "\n",
    "add_final   = add * add_softmax\n",
    "mult_final  = mult * mult_softmax\n",
    "stall_final = stall * stall_softmax\n",
    "\n",
    "##conact add and mult results with zeros matrix\n",
    "add_final = tf.concat([add_final, tf.slice(dummy_matrix, [0,0], [batch_size, num_features - add_width])], 1) \n",
    "mult_final = tf.concat([mult_final, tf.slice(dummy_matrix, [0,0], [batch_size, num_features - mult_width])], 1) \n",
    "\n",
    "output_final = add_final + mult_final + stall_final \n",
    "\n",
    "print(add_width.eval())\n",
    "print(mult_width.eval())\n",
    "print(stall_width.eval())\n",
    "\n",
    "\n",
    "print(add.eval())\n",
    "print(mult.eval())\n",
    "print(stall.eval())\n",
    "\n",
    "print(add_softmax.eval())\n",
    "print(mult_softmax.eval())\n",
    "print(stall_softmax.eval())\n",
    "\n",
    "print(add_final.eval())\n",
    "print(mult_final.eval())\n",
    "print(stall_final.eval())\n",
    "\n",
    "print(output_final.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[         inf]\n",
      " [ 52.62382889]\n",
      " [ 67.75031281]\n",
      " [ 74.36369324]\n",
      " [ 80.97130585]]\n",
      "[[             inf]\n",
      " [  7.14890146e+22]\n",
      " [  2.65208442e+29]\n",
      " [  1.97579466e+32]\n",
      " [  1.46349014e+35]]\n",
      "[[  3.84333611e+01   9.29976349e+01   7.14285660e+01   4.66166191e+01]\n",
      " [  4.27255707e+01   5.26204147e+01   4.69276009e+01   3.90492363e+01]\n",
      " [  5.37128487e+01   3.58061447e+01   6.77503128e+01   8.62670392e-02]\n",
      " [  7.43373108e+01   6.39807472e+01   7.07143021e+01   4.91895981e+01]\n",
      " [  8.07342987e+01   7.54765930e+01   7.93957977e+01   5.77571068e+01]]\n",
      "[[ 0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def custom_softmax(inpt):\n",
    "    sum_exponents = tf.reduce_sum(tf.exp(inpt), axis = 1)\n",
    "    soft_max = tf.log(sum_exponents)\n",
    "    soft_max = tf.reshape( soft_max, [batch_size, -1])\n",
    "    print(soft_max.eval())\n",
    "    matrix_width = tf.cast(tf.shape(inpt)[1], tf.int32)\n",
    "    multiples = [1, matrix_width]\n",
    "    soft_max = tf.tile(soft_max, multiples)\n",
    "    return  tf.reshape( inpt / soft_max, [batch_size, -1])\n",
    "\n",
    "def custom_softmax2(inpt):\n",
    "    sum_exponents = tf.reduce_sum(tf.exp(inpt), axis = 1)\n",
    "    soft_max = sum_exponents\n",
    "    soft_max = tf.reshape( soft_max, [batch_size, -1])\n",
    "    print(soft_max.eval())\n",
    "    matrix_width = tf.cast(tf.shape(inpt)[1], tf.int32)\n",
    "    multiples = [1, matrix_width]\n",
    "    soft_max = tf.tile(soft_max, multiples)\n",
    "    return  tf.reshape( tf.exp(inpt) / soft_max, [batch_size, -1])\n",
    "x_cust = custom_softmax(x)\n",
    "x_cust2 = custom_softmax2(x)\n",
    "print(x.eval())\n",
    "#print(x_cust2.eval())\n",
    "print(tf.nn.softmax(x*10000).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
