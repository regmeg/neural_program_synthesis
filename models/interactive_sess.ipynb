{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "gloabal_seed = round(random.random()*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97943"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(gloabal_seed)\n",
    "tf.set_random_seed(gloabal_seed)\n",
    "sess = tf.InteractiveSession()\n",
    "num_features = 3\n",
    "num_samples = 5\n",
    "state_size = 4\n",
    "num_of_operations = 3\n",
    "batch_size = num_samples\n",
    "max_num_features = 10\n",
    "datatype = tf.float64\n",
    "\n",
    "\n",
    "#model placeholders\n",
    "batchX_placeholder = tf.placeholder(datatype, [batch_size, None], name=\"batchX\")\n",
    "batchY_placeholder = tf.placeholder(datatype, [batch_size, None], name=\"batchY\")\n",
    "\n",
    "def add(vec):\n",
    "    return reduce((lambda x, y: x + y),vec)\n",
    "\n",
    "def samples_generator(fn, shape, rng, seed=None):\n",
    "    '''\n",
    "    Generate random samples for the model:\n",
    "    @fn - function to be applied on the input features to get the ouput\n",
    "    @shape - shape of the features matrix (num_samples, num_features)\n",
    "    @rng - range of the input features to be generated within (a,b)\n",
    "    @seed  - generation seed\n",
    "    Outputs a tuple of input and output features matrix\n",
    "    '''\n",
    "    x = (rng[1] - rng[0]) * np.random.random_sample(shape) + rng[0]\n",
    "    y = np.apply_along_axis(fn, 1, x).reshape((shape[0],-1))\n",
    "    z = np.zeros((shape[0],shape[1] - y.shape[1]))\n",
    "    y = np.concatenate((y, z), axis=1)\n",
    "    '''\n",
    "    j = -1\n",
    "    for i,x_i in enumerate(x):\n",
    "        j = j +1 \n",
    "        if j > num_features -1: j = 0\n",
    "        print(i,j)\n",
    "        x[i,j] = 0\n",
    "    '''\n",
    "\n",
    "    return x,y\n",
    "\n",
    "\n",
    "_x,_y = samples_generator(add, (num_samples, num_features) , (0, 100))\n",
    "\n",
    "def tf_multiply(inpt):\n",
    "    return tf.reshape( tf.reduce_prod(inpt, axis = 1), [batch_size, -1])\n",
    "num_features\n",
    "def tf_add(inpt):\n",
    "    return  tf.reshape( tf.reduce_sum(inpt, axis = 1), [batch_size, -1])\n",
    "\n",
    "def tf_stall(a):\n",
    "    return a\n",
    "\n",
    "W_te = tf.Variable(tf.truncated_normal([state_size, num_of_operations], -1*5, 5, dtype=datatype),dtype=datatype, name=\"W2\")\n",
    "\n",
    "x = tf.Variable(_x, dtype=datatype)\n",
    "y = tf.Variable(_y, dtype=datatype)\n",
    "W_te.initializer.run()\n",
    "x.initializer.run()\n",
    "y.initializer.run()\n",
    "\n",
    "gloabal_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def not_zero(inpt, pinpt=None):\n",
    "        greater = tf.greater(inpt,tf.zeros_like(inpt, dtype=datatype))\n",
    "        less = tf.less(inpt, tf.zeros_like(inpt, dtype=datatype))\n",
    "        not_zero = tf.logical_or(greater, less)\n",
    "        return not_zero\n",
    "\n",
    "\n",
    "def tf_multiply(inpt, pinpt=None):\n",
    "        result = tf.reduce_prod(inpt, axis = 1, name = \"tf_mult\")\n",
    "        reshape = tf.reshape(result , [batch_size, -1], name = \"tf_mult_reshape\")\n",
    "        pad_res = tf.pad(reshape, [[0,0],[0,num_features - 1]], \"CONSTANT\", name=\"tf_mult_pad\")\n",
    "        return pad_res\n",
    "\n",
    "def tf_divide(inpt, pinpt=None):\n",
    "        repriocal = tf.reciprocal(inpt)\n",
    "        reg_slice = tf.slice(inpt, [0,0], [batch_size,1])\n",
    "        repr_slice = tf.slice(repriocal, [0,1], [batch_size,num_features-1])\n",
    "        intp  = tf.concat([reg_slice, repr_slice],1)\n",
    "        masked_ones = tf.where(tf.is_inf(intp), tf.ones_like(inpt, dtype=datatype), intp)\n",
    "        return tf_multiply(masked_ones)\n",
    "\n",
    "\n",
    "\n",
    "equl = tf_divide(x)\n",
    "equl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "add    = tf_add(x)\n",
    "mult   = tf_multiply(x)\n",
    "stall  = tf_stall(x)\n",
    "values = tf.concat([add, mult, stall], 1)\n",
    "#print(values.eval())\n",
    "#padding = tf.constant()\n",
    "print(add.eval())\n",
    "print(mult.eval())\n",
    "print(stall.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init_state = tf.Variable(np.zeros([batch_size, state_size]), dtype=datatype)\n",
    "argmax_dum = tf.Variable([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],  dtype=datatype)\n",
    "W = tf.Variable(np.random.rand(state_size+num_features, state_size), dtype=datatype)\n",
    "b = tf.Variable(np.zeros((state_size)), dtype=datatype)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_of_operations),dtype=datatype)\n",
    "b2 = tf.Variable(np.zeros((num_of_operations)), dtype=datatype)\n",
    "\n",
    "dummy_matrix = tf.zeros([batch_size, num_features], datatype, name=\"dummy_constant\")\n",
    "\n",
    "init_state.initializer.run()\n",
    "argmax_dum.initializer.run()\n",
    "W.initializer.run()\n",
    "b.initializer.run()\n",
    "W2.initializer.run()\n",
    "b2.initializer.run()\n",
    "#dummy_matrix.initializer.run()\n",
    "\n",
    "current_state = init_state\n",
    "current_input = x\n",
    "      \n",
    "input_and_state_concatenated = tf.concat([current_input, current_state], 1)  # Increasing number of columns\n",
    "next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "current_state = next_state\n",
    "    \n",
    "    #calculate softmax and produce the mask of operations\n",
    "logits  = tf.matmul(next_state, W2) + b2 #Broadcasted addition\n",
    "softmax = tf.nn.softmax(logits)\n",
    "softmax_10000 = tf.nn.softmax(logits)\n",
    "softplus = tf.nn.softplus(logits)\n",
    "softsign = tf.nn.softsign(logits)\n",
    "argmax  = tf.argmax(softmax, 1)\n",
    "\n",
    "#lengths_transposed = tf.expand_dims(argmax, 0)\n",
    "#onehot  = tf.one_hot(argmax, num_of_operations)\n",
    "stall_width = tf.shape(stall)[1] - 1 \n",
    "stall_select = tf.slice(softmax, [0,2], [batch_size,1])\n",
    "multiples = [1, stall_width]\n",
    "stall_mask = tf.tile(stall_select, multiples)\n",
    "mask = tf.concat([softmax, stall_mask], 1)\n",
    "#mask = tf.cast(mask, tf.bool)\n",
    "#apply mask\n",
    "#output = tf.boolean_mask(values,mask)\n",
    "output = values * mask\n",
    "nn_soft = tf.nn.softmax(logits)\n",
    "output_width = tf.shape(output)[1]\n",
    "#zeros_slice = tf.slice(dummy_matrix, [0,0], [batch_size, max_num_features - output_width])\n",
    "#dum_plus_input = tf.concat([output, zeros_slice], 1)\n",
    "#print(dum_plus_input.eval())\n",
    "\n",
    "'''\n",
    "print(x.eval())\n",
    "print(\"stall_select\")\n",
    "print(stall_select.eval())\n",
    "print(\"mask\")\n",
    "print(mask.eval())\n",
    "print(\"logits\")\n",
    "print(logits.eval())\n",
    "print(\"softmax\")\n",
    "print(softmax.eval())\n",
    "print(\"softplus\")\n",
    "print(softplus.eval())\n",
    "print(\"softsign\")\n",
    "print(softsign.eval())\n",
    "print(\"softmax*10000\")\n",
    "print(softmax_10000.eval())\n",
    "print(\"onehot\")\n",
    "print(onehot.eval())\n",
    "'''\n",
    "#print(mask.eval())\n",
    "#print(mask.eval())\n",
    "#print(output.eval())\n",
    "print(softmax.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "add_softmax   = tf.slice(softmax, [0,0], [batch_size,1])\n",
    "mult_softmax  = tf.slice(softmax, [0,1], [batch_size,1])\n",
    "stall_softmax = tf.slice(softmax, [0,2], [batch_size,1])\n",
    "\n",
    "'''\n",
    "print(add_softmax.eval())\n",
    "print(mult_softmax.eval())\n",
    "print(stall_softmax.eval())\n",
    "'''\n",
    "print(softmax.eval())\n",
    "print(softmax[1].eval())\n",
    "print(softmax[2].eval())\n",
    "\n",
    "add_width   = tf.shape(add)[1]\n",
    "mult_width  = tf.shape(mult)[1]\n",
    "stall_width = tf.shape(stall)[1]\n",
    "\n",
    "add_final = tf.pad(add, [[0,0],[0,num_features - add_width]], \"CONSTANT\") \n",
    "mult_final = tf.pad(mult, [[0,0],[0,num_features - mult_width]], \"CONSTANT\") \n",
    "stall_final = tf.pad(stall, [[0,0],[0,num_features - stall_width]], \"CONSTANT\")\n",
    "\n",
    "#print(softmax.eval())\n",
    "\n",
    "print(add_final.eval())\n",
    "print(mult_final.eval())\n",
    "print(stall_final.eval())\n",
    "\n",
    "#tf.multiply()\n",
    "add_final   = tf.multiply(add_final, softmax[0])\n",
    "mult_final  = tf.multiply(mult_final, softmax[1])\n",
    "stall_final = tf.multiply(stall_final, softmax[2])\n",
    "\n",
    "print(add_final.eval())\n",
    "print(mult_final.eval())\n",
    "print(stall_final.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "add_width   = tf.shape(add)[1]\n",
    "mult_width  = tf.shape(mult)[1]\n",
    "stall_width = tf.shape(stall)[1]\n",
    "\n",
    "\n",
    "add_final   = add * add_softmax\n",
    "mult_final  = mult * mult_softmax\n",
    "stall_final = stall * stall_softmax\n",
    "\n",
    "##conact add and mult results with zeros matrix\n",
    "add_final = tf.concat([add_final, tf.slice(dummy_matrix, [0,0], [batch_size, num_features - add_width])], 1) \n",
    "mult_final = tf.concat([mult_final, tf.slice(dummy_matrix, [0,0], [batch_size, num_features - mult_width])], 1) \n",
    "\n",
    "output_final = add_final + mult_final + stall_final \n",
    "\n",
    "print(add_width.eval())\n",
    "print(mult_width.eval())\n",
    "print(stall_width.eval())\n",
    "\n",
    "\n",
    "print(add.eval())\n",
    "print(mult.eval())\n",
    "print(stall.eval())\n",
    "\n",
    "print(add_softmax.eval())\n",
    "print(mult_softmax.eval())\n",
    "print(stall_softmax.eval())\n",
    "\n",
    "print(add_final.eval())\n",
    "print(mult_final.eval())\n",
    "print(stall_final.eval())\n",
    "\n",
    "print(output_final.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_softmax(inpt):\n",
    "    sum_exponents = tf.reduce_sum(tf.exp(inpt), axis = 1)\n",
    "    soft_max = tf.log(sum_exponents)\n",
    "    soft_max = tf.reshape( soft_max, [batch_size, -1])\n",
    "    print(soft_max.eval())\n",
    "    matrix_width = tf.cast(tf.shape(inpt)[1], tf.int32)\n",
    "    multiples = [1, matrix_width]\n",
    "    soft_max = tf.tile(soft_max, multiples)\n",
    "    return  tf.reshape( inpt / soft_max, [batch_size, -1])\n",
    "\n",
    "def custom_softmax2(inpt):\n",
    "    sum_exponents = tf.reduce_sum(tf.exp(inpt), axis = 1)\n",
    "    soft_max = sum_exponents\n",
    "    soft_max = tf.reshape( soft_max, [batch_size, -1])\n",
    "    print(soft_max.eval())\n",
    "    matrix_width = tf.cast(tf.shape(inpt)[1], tf.int32)\n",
    "    multiples = [1, matrix_width]\n",
    "    soft_max = tf.tile(soft_max, multiples)\n",
    "    return  tf.reshape( tf.exp(inpt) / soft_max, [batch_size, -1])\n",
    "x_cust = custom_softmax(x)\n",
    "x_cust2 = custom_softmax2(x)\n",
    "print(x.eval())\n",
    "#print(x_cust2.eval())\n",
    "print(tf.nn.softmax(x*10000).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "math_error = tf.multiply(tf.constant(0.5, dtype=datatype), tf.square(tf.subtract(tf.reduce_sum(output, axis = 1, name=\"red_output\") , batchY_placeholder, name=\"sub_otput_batchY\"), name=\"squar_error\"), name=\"mult_with_0.5\")\n",
    "\n",
    "total_loss = tf.reduce_sum(math_error, name=\"red_total_loss\")\n",
    "\n",
    "grads = tf.gradients(total_loss, [W,b,W2,b2], name=\"comp_gradients\")\n",
    "train_step = tf.train.AdamOptimizer(0.1, name=\"AdamOpt\").minimize(total_loss, name=\"min_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(output):\n",
    "    #reduced_output = tf.reshape( tf.reduce_sum(output, axis = 1, name=\"red_output\"), [batch_size, -1])\n",
    "    math_error = tf.multiply(tf.constant(0.5, dtype=datatype), tf.square(tf.subtract(output , y, name=\"sub_otput_batchY\"), name=\"squar_error\"), name=\"mult_with_0.5\")\n",
    "    \n",
    "                             \n",
    "    total_loss = tf.reduce_sum(math_error, name=\"red_total_loss\")\n",
    "    return total_loss, math_error\n",
    "\n",
    "\n",
    "loss, mathh = calc_loss(output_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mathh.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prng.random_sample((10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "q = tf.FIFOQueue(capacity=2, dtypes=datatype)\n",
    "q.enqueue(x)\n",
    "q.dequeue().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for batch_idx in range(num_batches):\n",
    "            start_idx = batch_size * batch_idx\n",
    "            end_idx   = batch_size * batch_idx + batch_idx\n",
    "\n",
    "            batchX = x[start_idx:end_idx]\n",
    "            batchY = y[start_idx:end_idx]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_x_ = tf.constant(_x, dtype=datatype, name=\"ROM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_x_.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ops import Operations\n",
    "import pickle\n",
    "from data_gen import samples_generator, split_train_test, np_avg_val, shuffle_data\n",
    "import tensorflow as tf\n",
    "#path = '/home/user/neural_program_synthesis/models/summaries/RNN/np_mult-5ops/200_state_size-1500_num_samples-100_batch_size-0.005_learning_rate-1000.0_grad_norm-3_num_features-True_norm-True_share_state-3388_seed/'\n",
    "#get the global configuration\n",
    "#cfg_path = path+'cfg.p'\n",
    "#cfg = pickle.load(open(cfg_path, 'rb'))\n",
    "\n",
    "cfg = dict(\n",
    "        num_samples = 100,\n",
    "        batch_size  = 100,\n",
    "        num_features = 4,\n",
    "        datatype = tf.float64,\n",
    "        train_fn = np_avg_val,\n",
    "        samples_value_rng = (-100,100),\n",
    "        seed = 12345,\n",
    "        test_ratio = 0\n",
    "    )\n",
    "\n",
    "class Self:\n",
    "    cfg = cfg\n",
    "\n",
    "ops = Operations(cfg)\n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], cfg['seed'])\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "\n",
    "'''\n",
    "x = np.array([[ 23.189, -42.002, -26.452, -15.725],\n",
    "       [-95.63 , -79.073,  24.234, -85.237],\n",
    "       [ 60.3  , -94.363, -42.833, -71.845],\n",
    "       [ 74.98 ,  -5.963,  35.756, -16.65 ],\n",
    "       [ -6.447,  44.767,  94.382, -67.512],\n",
    "       [ -9.713, -24.038, -13.356, -21.131],\n",
    "       [ 53.432,  67.814,  78.293,  48.176],\n",
    "       [-23.986, -58.781,  80.475, -34.266],\n",
    "       [-57.382,  87.057, -25.952, -90.51 ],\n",
    "       [ 36.822,  64.372, -27.093,  50.29 ],\n",
    "       [-68.925, -22.739,  31.911,  72.149],\n",
    "       [ 14.825, -58.94 ,  50.581,  83.449],\n",
    "       [-93.297, -86.347,  -7.563, -93.027],\n",
    "       [ 96.274,  65.179,  20.911,  19.269],\n",
    "       [ 25.263,  76.374,  70.884,  10.462],\n",
    "       [-10.132, -77.352,  14.843,  40.792],\n",
    "       [ 84.287,  68.528, -12.832, -86.109],\n",
    "       [ 99.117,  58.735,  68.907, -15.914],\n",
    "       [ 17.553, -67.552,  14.866, -43.754],\n",
    "       [-33.589,  27.387,  -6.556,  12.338],\n",
    "       [ 77.52 ,  11.511,  76.939, -70.807],\n",
    "       [ 32.167, -93.357, -98.895, -48.986],\n",
    "       [ 68.577,  69.543, -74.404,  -4.024],\n",
    "       [ 70.2  ,  82.825,   8.305, -71.302],\n",
    "       [-44.041, -75.352,  95.073, -87.54 ],\n",
    "       [ 25.98 , -87.646, -11.701,  56.768],\n",
    "       [ 76.008,  60.494,  53.167, -49.42 ],\n",
    "       [ -7.815,  23.902, -20.015, -79.006],\n",
    "       [-94.983, -17.819,  -2.067,  23.126],\n",
    "       [-54.636,  -2.539,  20.931, -94.096],\n",
    "       [ 68.149,  79.372, -86.202,  76.742],\n",
    "       [-14.796,  64.989,  58.817, -83.301],\n",
    "       [-25.414, -86.643,  61.771,  98.426],\n",
    "       [ 10.173,  48.92 ,  93.036, -80.249],\n",
    "       [-13.089,  26.746,  87.876,  94.592],\n",
    "       [ 45.603,  85.894, -47.612,  -6.787],\n",
    "       [ 46.793, -26.193,  -4.677, -59.749],\n",
    "       [-20.213,  79.535, -44.217, -88.696],\n",
    "       [  3.407,  56.859, -26.391,  12.307],\n",
    "       [-24.959,  70.993, -89.733,  87.929],\n",
    "       [-18.904, -13.668,  41.101, -47.656],\n",
    "       [-53.441, -17.277, -12.676,  71.409],\n",
    "       [-18.813, -11.732, -76.122, -67.408],\n",
    "       [ 47.552,  41.597, -36.941,  73.937],\n",
    "       [-64.924,  59.681, -81.812, -82.904],\n",
    "       [ 95.358,  66.568,  -8.738,   9.439],\n",
    "       [ 93.185,   2.808,  29.391,  39.588],\n",
    "       [-99.219,  24.58 ,  54.582,  80.662],\n",
    "       [ 64.292, -57.929,  95.307,  90.874],\n",
    "       [ 57.414,  37.394,  75.583, -19.582],\n",
    "       [ 15.319,  30.597, -30.806,  29.242],\n",
    "       [-65.569,   1.716, -16.576,  63.058],\n",
    "       [ 70.369, -61.159,  78.434,  89.286],\n",
    "       [ 67.537, -52.961,  79.777, -93.552],\n",
    "       [-16.658,  90.221,  59.723,  75.797],\n",
    "       [ 42.219, -99.972, -83.024,  88.062],\n",
    "       [-72.864,  57.878,  -2.289,  34.014],\n",
    "       [-94.008,  88.845, -66.88 , -71.385],\n",
    "       [-14.435, -77.109,  79.578,   7.717],\n",
    "       [-15.654,  95.881, -84.344, -97.908],\n",
    "       [ 64.431,  69.045,   3.123,  84.139],\n",
    "       [ 64.304,  31.814,  -8.241, -58.181],\n",
    "       [ 37.104,  60.072, -91.869,  91.541],\n",
    "       [-52.595,  58.635, -60.942, -11.734],\n",
    "       [ 47.192,  60.29 ,  29.391,  89.29 ],\n",
    "       [  3.848,  92.222, -91.473,  14.821],\n",
    "       [-63.22 , -77.426, -16.128,  69.829],\n",
    "       [ 91.381,  -4.997, -39.724, -89.213],\n",
    "       [-80.447, -95.644, -29.996,  -1.83 ],\n",
    "       [ 39.474, -78.517, -10.864, -84.873],\n",
    "       [-33.316,  84.983, -57.971, -72.246],\n",
    "       [-97.971, -93.116, -88.513, -35.676],\n",
    "       [ -5.022, -83.479, -61.179,  41.852],\n",
    "       [ -4.378, -13.434,  32.945,  14.324],\n",
    "       [ 62.571, -23.528, -19.708,  50.382],\n",
    "       [ 39.94 ,  45.152, -95.465,  89.402],\n",
    "       [ 73.733, -66.974, -81.308, -19.99 ],\n",
    "       [-87.966,  77.257, -11.255,  86.341],\n",
    "       [  5.799,  48.814, -82.306,  45.7  ],\n",
    "       [ 62.373,  51.08 ,  35.513, -42.867],\n",
    "       [ -4.329, -59.876,  90.674, -45.843],\n",
    "       [-92.764,  76.665,  82.624, -37.427],\n",
    "       [-99.088, -27.399, -16.514,  -4.89 ],\n",
    "       [-47.25 ,  65.88 ,  95.401,  94.093],\n",
    "       [ 26.498,  75.795,  77.982,  77.405],\n",
    "       [ 16.217,  58.304, -99.593,  90.281],\n",
    "       [-19.658, -70.787, -86.378, -84.604],\n",
    "       [ -9.152,  90.501,  38.061,  86.036],\n",
    "       [ 86.581,  43.947, -23.602,  -4.719],\n",
    "       [-31.208, -78.595, -49.932,  29.811],\n",
    "       [ 39.817, -82.113, -97.876,  71.594],\n",
    "       [-28.101, -87.935,  99.316,  12.622],\n",
    "       [-26.876,  78.519,  57.279,  85.709],\n",
    "       [-35.139, -29.972,  13.563, -58.462],\n",
    "       [ 73.982, -19.079,  -7.627, -59.98 ],\n",
    "       [ 79.952, -63.802,  86.559, -61.022],\n",
    "       [ 64.827, -46.69 , -82.259, -61.805],\n",
    "       [ 71.393,  60.95 ,  20.226,   7.915],\n",
    "       [-23.635,  64.426,  13.434, -52.965],\n",
    "       [-43.368, -54.169, -87.451, -40.26 ]])\n",
    "'''\n",
    "\n",
    "\n",
    "ops = Operations(cfg)\n",
    "\n",
    "\n",
    "_len = ops.ops[0](x).eval()\n",
    "_div = ops.ops[1](x, x).eval()\n",
    "_sum = ops.ops[2](x).eval()\n",
    "\n",
    "_avg = ops.ops[1](_sum, _len).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  7.10542736e-15,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  3.55271368e-15,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  3.55271368e-15,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.42108547e-14,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [ -1.77635684e-15,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [ -3.55271368e-15,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y - _avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tf_inpt_len(self,inpt, mem_sel=None):\n",
    "        with tf.name_scope(\"tf_inpt_len\"):\n",
    "            masked_zeros = tf.where( tf.equal(inpt,tf.zeros_like(inpt, dtype=self.cfg['datatype'])), tf.ones_like(inpt, dtype=self.cfg['datatype']), inpt, name=\"clean_zeros\")\n",
    "            inpt_ones = tf.divide(masked_zeros, masked_zeros, name=\"produce_ones\")\n",
    "            result = tf.reduce_sum(inpt_ones, axis = 1, name = \"len_reduce\")\n",
    "            reshape = tf.reshape(result, [self.cfg['batch_size'], -1], name = \"reshape\")\n",
    "            pad_res = tf.pad(reshape, [[0,0],[0,self.cfg['num_features'] - 1]], \"CONSTANT\", name=\"pad\")\n",
    "            return  pad_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = samples_generator(np_avg_val, (100, 4) , (-100, 100), 100)\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , 0.33)\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_x = tf.Variable(x, dtype=datatype)\n",
    "_y = tf.Variable(y, dtype=datatype)\n",
    "_x.initializer.run()\n",
    "_y.initializer.run()\n",
    "\n",
    "tf_inpt_len(Self,_y, _x).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ops import Operations\n",
    "ops.num_of_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.ones_like(_x, dtype=cfg['datatype'],  name=\"tf_inpt_len_assign_ones\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x,y = samples_generator(np_avg_val, (8, 2) , (-100, 100), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_x,_y = shuffle_data(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
