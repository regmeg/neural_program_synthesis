{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "gloabal_seed = round(random.random()*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95710"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(gloabal_seed)\n",
    "tf.set_random_seed(gloabal_seed)\n",
    "sess = tf.InteractiveSession()\n",
    "num_features = 2\n",
    "num_samples = 5\n",
    "state_size = 4\n",
    "num_of_operations = 3\n",
    "batch_size = num_samples\n",
    "max_num_features = 10\n",
    "datatype = tf.float64\n",
    "\n",
    "\n",
    "#model placeholders\n",
    "batchX_placeholder = tf.placeholder(datatype, [batch_size, None], name=\"batchX\")\n",
    "batchY_placeholder = tf.placeholder(datatype, [batch_size, None], name=\"batchY\")\n",
    "\n",
    "def add(vec):\n",
    "    return reduce((lambda x, y: x + y),vec)\n",
    "\n",
    "def samples_generator(fn, shape, rng, seed=None):\n",
    "    '''\n",
    "    Generate random samples for the model:\n",
    "    @fn - function to be applied on the input features to get the ouput\n",
    "    @shape - shape of the features matrix (num_samples, num_features)\n",
    "    @rng - range of the input features to be generated within (a,b)\n",
    "    @seed  - generation seed\n",
    "    Outputs a tuple of input and output features matrix\n",
    "    '''\n",
    "    x = (rng[1] - rng[0]) * np.random.random_sample(shape) + rng[0]\n",
    "    y = np.apply_along_axis(fn, 1, x).reshape((shape[0],-1))\n",
    "    z = np.zeros((shape[0],shape[1] - y.shape[1]))\n",
    "    y = np.concatenate((y, z), axis=1)\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "\n",
    "_x,_y = samples_generator(add, (num_samples, num_features) , (0, 100))\n",
    "\n",
    "def tf_multiply(inpt):\n",
    "    return tf.reshape( tf.reduce_prod(inpt, axis = 1), [batch_size, -1])\n",
    "\n",
    "def tf_add(inpt):\n",
    "    return  tf.reshape( tf.reduce_sum(inpt, axis = 1), [batch_size, -1])\n",
    "\n",
    "def tf_stall(a):\n",
    "    return a\n",
    "\n",
    "W_te = tf.Variable(tf.truncated_normal([state_size, num_of_operations], -1*5, 5, dtype=datatype),dtype=datatype, name=\"W2\")\n",
    "\n",
    "x = tf.Variable(_x, dtype=datatype)\n",
    "y = tf.Variable(_y, dtype=datatype)\n",
    "W_te.initializer.run()\n",
    "x.initializer.run()\n",
    "y.initializer.run()\n",
    "\n",
    "gloabal_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85.740326  ,  44.32875629],\n",
       "       [ 33.66475387,  22.86815549],\n",
       "       [ 39.99379103,  98.83167477],\n",
       "       [ 92.74805069,  77.79706293],\n",
       "       [ 34.41537659,  33.29722702]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W2:0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_te.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   69.49294147   971.52871758    19.39106417    50.1018773 ]\n",
      " [  166.88588423  6823.67250627    71.6509074     95.23497683]\n",
      " [   65.99332048  1084.57801535    35.04643384    30.94688665]\n",
      " [  132.78465568  4386.72066975    70.99890206    61.78575362]\n",
      " [   85.12652957  1051.88323565    70.12679637    14.9997332 ]]\n"
     ]
    }
   ],
   "source": [
    "add    = tf_add(x)\n",
    "mult   = tf_multiply(x)\n",
    "stall  = tf_stall(x)\n",
    "values = tf.concat([add, mult, stall], 1)\n",
    "print(values.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"sub_6:0\", shape=(), dtype=int32) must be from the same graph as Tensor(\"Slice:0\", shape=(5, 1), dtype=float64).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-08be25c7432b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mstall_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmultiples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstall_width\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mstall_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstall_select\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstall_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#mask = tf.cast(mask, tf.bool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m   3727\u001b[0m   \"\"\"\n\u001b[1;32m   3728\u001b[0m   result = _op_def_lib.apply_op(\"Tile\", input=input, multiples=multiples,\n\u001b[0;32m-> 3729\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   3730\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    328\u001b[0m       \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   4174\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4175\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4176\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4177\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4178\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   4113\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m     raise ValueError(\n\u001b[0;32m-> 4115\u001b[0;31m         \"%s must be from the same graph as %s.\" % (item, original_item))\n\u001b[0m\u001b[1;32m   4116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"sub_6:0\", shape=(), dtype=int32) must be from the same graph as Tensor(\"Slice:0\", shape=(5, 1), dtype=float64)."
     ]
    }
   ],
   "source": [
    "init_state = tf.Variable(np.zeros([batch_size, state_size]), dtype=datatype)\n",
    "argmax_dum = tf.Variable([2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],  dtype=datatype)\n",
    "W = tf.Variable(np.random.rand(state_size+num_features, state_size), dtype=datatype)\n",
    "b = tf.Variable(np.zeros((state_size)), dtype=datatype)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_of_operations),dtype=datatype)\n",
    "b2 = tf.Variable(np.zeros((num_of_operations)), dtype=datatype)\n",
    "\n",
    "dummy_matrix = tf.zeros([batch_size, num_features], datatype, name=\"dummy_constant\")\n",
    "\n",
    "init_state.initializer.run()\n",
    "argmax_dum.initializer.run()\n",
    "W.initializer.run()\n",
    "b.initializer.run()\n",
    "W2.initializer.run()\n",
    "b2.initializer.run()\n",
    "#dummy_matrix.initializer.run()\n",
    "\n",
    "current_state = init_state\n",
    "current_input = x\n",
    "      \n",
    "input_and_state_concatenated = tf.concat([current_input, current_state], 1)  # Increasing number of columns\n",
    "next_state = tf.tanh(tf.matmul(input_and_state_concatenated, W) + b)  # Broadcasted addition\n",
    "current_state = next_state\n",
    "    \n",
    "    #calculate softmax and produce the mask of operations\n",
    "logits  = tf.matmul(next_state, W2) + b2 #Broadcasted addition\n",
    "softmax = tf.nn.softmax(logits)\n",
    "softmax_10000 = tf.nn.softmax(logits)\n",
    "softplus = tf.nn.softplus(logits)\n",
    "softsign = tf.nn.softsign(logits)\n",
    "argmax  = tf.argmax(softmax, 1)\n",
    "\n",
    "#lengths_transposed = tf.expand_dims(argmax, 0)\n",
    "#onehot  = tf.one_hot(argmax, num_of_operations)\n",
    "stall_width = tf.shape(stall)[1] - 1 \n",
    "stall_select = tf.slice(softmax, [0,2], [batch_size,1])\n",
    "multiples = [1, stall_width]\n",
    "stall_mask = tf.tile(stall_select, multiples)\n",
    "mask = tf.concat([softmax, stall_mask], 1)\n",
    "#mask = tf.cast(mask, tf.bool)\n",
    "#apply mask\n",
    "#output = tf.boolean_mask(values,mask)\n",
    "output = values * mask\n",
    "nn_soft = tf.nn.softmax(logits)\n",
    "output_width = tf.shape(output)[1]\n",
    "#zeros_slice = tf.slice(dummy_matrix, [0,0], [batch_size, max_num_features - output_width])\n",
    "#dum_plus_input = tf.concat([output, zeros_slice], 1)\n",
    "#print(dum_plus_input.eval())\n",
    "\n",
    "'''\n",
    "print(x.eval())\n",
    "print(\"stall_select\")\n",
    "print(stall_select.eval())\n",
    "print(\"mask\")\n",
    "print(mask.eval())\n",
    "print(\"logits\")\n",
    "print(logits.eval())\n",
    "print(\"softmax\")\n",
    "print(softmax.eval())\n",
    "print(\"softplus\")\n",
    "print(softplus.eval())\n",
    "print(\"softsign\")\n",
    "print(softsign.eval())\n",
    "print(\"softmax*10000\")\n",
    "print(softmax_10000.eval())\n",
    "print(\"onehot\")\n",
    "print(onehot.eval())\n",
    "'''\n",
    "print(mask.eval())\n",
    "#print(mask.eval())\n",
    "#print(output.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "[[ 117.27246102]\n",
      " [ 130.35927593]\n",
      " [  20.56163332]\n",
      " [ 133.00636172]\n",
      " [  85.06563293]]\n",
      "[[ 2526.24220415]\n",
      " [ 3832.86768005]\n",
      " [   27.60618915]\n",
      " [ 3765.57772427]\n",
      " [  211.04370925]]\n",
      "[[ 28.43746689  88.83499413]\n",
      " [ 44.79539098  85.56388494]\n",
      " [ 19.11761484   1.44401848]\n",
      " [ 92.13705181  40.86930991]\n",
      " [  2.55786472  82.50776821]]\n",
      "[[ 0.11379326]\n",
      " [ 0.11379326]\n",
      " [ 0.11380242]\n",
      " [ 0.11379326]\n",
      " [ 0.11381671]]\n",
      "[[ 0.67884681]\n",
      " [ 0.67884681]\n",
      " [ 0.67881731]\n",
      " [ 0.67884681]\n",
      " [ 0.67882238]]\n",
      "[[ 0.20735993]\n",
      " [ 0.20735993]\n",
      " [ 0.20738027]\n",
      " [ 0.20735993]\n",
      " [ 0.20736091]]\n",
      "[[ 13.34481574   0.        ]\n",
      " [ 14.83400707   0.        ]\n",
      " [  2.33996372   0.        ]\n",
      " [ 15.1352276    0.        ]\n",
      " [  9.68189035   0.        ]]\n",
      "[[ 1714.93146007     0.        ]\n",
      " [ 2601.92999586     0.        ]\n",
      " [   18.73955895     0.        ]\n",
      " [ 2556.25042407     0.        ]\n",
      " [  143.2611927      0.        ]]\n",
      "[[  5.89679114  18.42081815]\n",
      " [  9.28876913  17.74252117]\n",
      " [  3.96461612   0.29946094]\n",
      " [ 19.10553259   8.47465723]\n",
      " [  0.53040116  17.10888613]]\n",
      "[[  1.73417307e+03   1.84208181e+01]\n",
      " [  2.62605277e+03   1.77425212e+01]\n",
      " [  2.50441388e+01   2.99460942e-01]\n",
      " [  2.59049118e+03   8.47465723e+00]\n",
      " [  1.53473484e+02   1.71088861e+01]]\n"
     ]
    }
   ],
   "source": [
    "add_softmax   = tf.slice(softmax, [0,0], [batch_size,1])\n",
    "mult_softmax  = tf.slice(softmax, [0,1], [batch_size,1])\n",
    "stall_softmax = tf.slice(softmax, [0,2], [batch_size,1])\n",
    "\n",
    "add_width   = tf.shape(add)[1]\n",
    "mult_width  = tf.shape(mult)[1]\n",
    "stall_width = tf.shape(stall)[1]\n",
    "\n",
    "\n",
    "add_final   = add * add_softmax\n",
    "mult_final  = mult * mult_softmax\n",
    "stall_final = stall * stall_softmax\n",
    "\n",
    "##conact add and mult results with zeros matrix\n",
    "add_final = tf.concat([add_final, tf.slice(dummy_matrix, [0,0], [batch_size, num_features - add_width])], 1) \n",
    "mult_final = tf.concat([mult_final, tf.slice(dummy_matrix, [0,0], [batch_size, num_features - mult_width])], 1) \n",
    "\n",
    "output_final = add_final + mult_final + stall_final \n",
    "\n",
    "print(add_width.eval())\n",
    "print(mult_width.eval())\n",
    "print(stall_width.eval())\n",
    "\n",
    "\n",
    "print(add.eval())\n",
    "print(mult.eval())\n",
    "print(stall.eval())\n",
    "\n",
    "print(add_softmax.eval())\n",
    "print(mult_softmax.eval())\n",
    "print(stall_softmax.eval())\n",
    "\n",
    "print(add_final.eval())\n",
    "print(mult_final.eval())\n",
    "print(stall_final.eval())\n",
    "\n",
    "print(output_final.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 88.83499413]\n",
      " [ 85.56388494]\n",
      " [ 19.11761486]\n",
      " [ 92.13705181]\n",
      " [ 82.50776821]]\n",
      "[[  3.80669209e+38]\n",
      " [  1.44518379e+37]\n",
      " [  2.00758824e+08]\n",
      " [  1.03422059e+40]\n",
      " [  6.80249839e+35]]\n",
      "[[ 28.43746689  88.83499413]\n",
      " [ 44.79539098  85.56388494]\n",
      " [ 19.11761484   1.44401848]\n",
      " [ 92.13705181  40.86930991]\n",
      " [  2.55786472  82.50776821]]\n",
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def custom_softmax(inpt):\n",
    "    sum_exponents = tf.reduce_sum(tf.exp(inpt), axis = 1)\n",
    "    soft_max = tf.log(sum_exponents)\n",
    "    soft_max = tf.reshape( soft_max, [batch_size, -1])\n",
    "    print(soft_max.eval())\n",
    "    matrix_width = tf.cast(tf.shape(inpt)[1], tf.int32)\n",
    "    multiples = [1, matrix_width]\n",
    "    soft_max = tf.tile(soft_max, multiples)\n",
    "    return  tf.reshape( inpt / soft_max, [batch_size, -1])\n",
    "\n",
    "def custom_softmax2(inpt):\n",
    "    sum_exponents = tf.reduce_sum(tf.exp(inpt), axis = 1)\n",
    "    soft_max = sum_exponents\n",
    "    soft_max = tf.reshape( soft_max, [batch_size, -1])\n",
    "    print(soft_max.eval())\n",
    "    matrix_width = tf.cast(tf.shape(inpt)[1], tf.int32)\n",
    "    multiples = [1, matrix_width]\n",
    "    soft_max = tf.tile(soft_max, multiples)\n",
    "    return  tf.reshape( tf.exp(inpt) / soft_max, [batch_size, -1])\n",
    "x_cust = custom_softmax(x)\n",
    "x_cust2 = custom_softmax2(x)\n",
    "print(x.eval())\n",
    "#print(x_cust2.eval())\n",
    "print(tf.nn.softmax(x*10000).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "math_error = tf.multiply(tf.constant(0.5, dtype=datatype), tf.square(tf.subtract(tf.reduce_sum(output, axis = 1, name=\"red_output\") , batchY_placeholder, name=\"sub_otput_batchY\"), name=\"squar_error\"), name=\"mult_with_0.5\")\n",
    "\n",
    "total_loss = tf.reduce_sum(math_error, name=\"red_total_loss\")\n",
    "\n",
    "grads = tf.gradients(total_loss, [W,b,W2,b2], name=\"comp_gradients\")\n",
    "train_step = tf.train.AdamOptimizer(0.1, name=\"AdamOpt\").minimize(total_loss, name=\"min_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(output):\n",
    "    #reduced_output = tf.reshape( tf.reduce_sum(output, axis = 1, name=\"red_output\"), [batch_size, -1])\n",
    "    math_error = tf.multiply(tf.constant(0.5, dtype=datatype), tf.square(tf.subtract(output , y, name=\"sub_otput_batchY\"), name=\"squar_error\"), name=\"mult_with_0.5\")\n",
    "    \n",
    "                             \n",
    "    total_loss = tf.reduce_sum(math_error, name=\"red_total_loss\")\n",
    "    return total_loss, math_error\n",
    "\n",
    "\n",
    "loss, mathh = calc_loss(output_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.30718378e+06,   1.69663271e+02],\n",
       "       [  3.11424301e+06,   1.57398529e+02],\n",
       "       [  1.00464276e+01,   4.48384279e-02],\n",
       "       [  3.01961583e+06,   3.59099076e+01],\n",
       "       [  2.33981706e+03,   1.46356992e+02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathh.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19151945,  0.62210877,  0.43772774,  0.78535858,  0.77997581],\n",
       "       [ 0.27259261,  0.27646426,  0.80187218,  0.95813935,  0.87593263],\n",
       "       [ 0.35781727,  0.50099513,  0.68346294,  0.71270203,  0.37025075],\n",
       "       [ 0.56119619,  0.50308317,  0.01376845,  0.77282662,  0.88264119],\n",
       "       [ 0.36488598,  0.61539618,  0.07538124,  0.36882401,  0.9331401 ],\n",
       "       [ 0.65137814,  0.39720258,  0.78873014,  0.31683612,  0.56809865],\n",
       "       [ 0.86912739,  0.43617342,  0.80214764,  0.14376682,  0.70426097],\n",
       "       [ 0.70458131,  0.21879211,  0.92486763,  0.44214076,  0.90931596],\n",
       "       [ 0.05980922,  0.18428708,  0.04735528,  0.67488094,  0.59462478],\n",
       "       [ 0.53331016,  0.04332406,  0.56143308,  0.32966845,  0.50296683]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prng.random_sample((10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.88666268,  34.73962374],\n",
       "       [ 40.79798811,  43.39526771]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "q = tf.FIFOQueue(capacity=2, dtypes=datatype)\n",
    "q.enqueue(x)\n",
    "q.dequeue().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for batch_idx in range(num_batches):\n",
    "            start_idx = batch_size * batch_idx\n",
    "            end_idx   = batch_size * batch_idx + batch_idx\n",
    "\n",
    "            batchX = x[start_idx:end_idx]\n",
    "            batchY = y[start_idx:end_idx]\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
