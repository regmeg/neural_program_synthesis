{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "norming the grads\n",
      "grads are\n",
      "[<tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_0:0' shape=(53, 50) dtype=float64>, <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_1:0' shape=(50,) dtype=float64>, <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_2:0' shape=(50, 3) dtype=float64>, <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_3:0' shape=(3,) dtype=float64>]\n",
      "num batches train: 10\n",
      "num batches test: 4\n",
      "INFO:tensorflow:Restoring parameters from ./summaries/np_add-5ops/test7/model/-1950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python import debug as tf_debug\n",
    "from tensorflow.python.framework import ops as tf_ops\n",
    "import pprint\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from data_gen import *\n",
    "from params import get_cfg\n",
    "from ops import Operations\n",
    "\n",
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope(var.name.replace(\":\",\"_\")):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    tf.summary.scalar('stddev', tf.sqrt(tf.reduce_mean(tf.square(var - mean))))\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "\n",
    "def write_no_tf_summary(writer, tag, val, step):\n",
    "   summary=tf.Summary()\n",
    "   summary.value.add(tag=tag, simple_value = val)\n",
    "   writer.add_summary(summary, step)\n",
    "    \n",
    "\n",
    "#helpder func\n",
    "def get_time_hhmmss(dif):\n",
    "    m, s = divmod(dif, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "    return time_str\n",
    "\n",
    "\n",
    "cfg = get_cfg()    \n",
    "ops = Operations(cfg)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#model constants\n",
    "dummy_matrix = tf.zeros([cfg['batch_size'], cfg['num_features']], dtype=cfg['datatype'], name=\"dummy_constant\")\n",
    "\n",
    "#model placeholders\n",
    "batchX_placeholder = tf.placeholder(cfg['datatype'], [cfg['batch_size'], None], name=\"batchX\")\n",
    "batchY_placeholder = tf.placeholder(cfg['datatype'], [cfg['batch_size'], None], name=\"batchY\")\n",
    "\n",
    "init_state = tf.placeholder(cfg['datatype'], [cfg['batch_size'], cfg['state_size']], name=\"init_state\")\n",
    "\n",
    "\n",
    "#set random seed\n",
    "tf.set_random_seed(cfg['seed'])\n",
    "\n",
    "#model parameters\n",
    "W = tf.Variable(tf.truncated_normal([cfg['state_size']+cfg['num_features'], cfg['state_size']], -1*cfg['param_init'], cfg['param_init'], dtype=cfg['datatype']), dtype=cfg['datatype'], name=\"W\")\n",
    "b = tf.Variable(np.zeros((cfg['state_size'])), dtype=cfg['datatype'], name=\"b\")\n",
    "variable_summaries(W)\n",
    "variable_summaries(b)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([cfg['state_size'], ops.num_of_ops], -1*cfg['param_init'], cfg['param_init'], dtype=cfg['datatype']),dtype=cfg['datatype'], name=\"W2\")\n",
    "b2 = tf.Variable(np.zeros((ops.num_of_ops)), dtype=cfg['datatype'], name=\"b2\")\n",
    "variable_summaries(W2)\n",
    "variable_summaries(b2)\n",
    "\n",
    "    #forward pass\n",
    "def run_forward_pass(mode=\"train\"):\n",
    "    current_state = init_state\n",
    "\n",
    "    output = batchX_placeholder\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    softmaxes = []\n",
    "    \n",
    "    #printtf = tf.Print(output, [output], message=\"Strated cycle\")\n",
    "    #output = tf.reshape( printtf, [batch_size, -1], name = \"dummu_rehap\")\n",
    "    \n",
    "    for timestep in range(cfg['max_output_ops']):\n",
    "        print(\"timestep \" + str(timestep))\n",
    "        current_input = output\n",
    "\n",
    "\n",
    "\n",
    "        input_and_state_concatenated = tf.concat([current_input, current_state], 1, name=\"concat_input_state\")  # Increasing number of columns\n",
    "        next_state = tf.tanh(tf.add(tf.matmul(input_and_state_concatenated, W, name=\"input-state_mult_W\"), b, name=\"add_bias\"), name=\"tanh_next_state\")  # Broadcasted addition\n",
    "        #next_state = tf.nn.relu(tf.add(tf.matmul(input_and_state_concatenated, W, name=\"input-state_mult_W\"), b, name=\"add_bias\"), name=\"relu_next-state\")  # Broadcasted addition\n",
    "        current_state = next_state\n",
    "\n",
    "        #calculate softmax and produce the mask of operations\n",
    "        logits = tf.add(tf.matmul(next_state, W2, name=\"state_mul_W2\"), b2, name=\"add_bias2\") #Broadcasted addition\n",
    "        softmax = tf.nn.softmax(logits, name=\"get_softmax\")\n",
    "        \n",
    "        #in test change to hardmax\n",
    "        if mode is \"test\":\n",
    "            argmax  = tf.argmax(softmax, 1, )\n",
    "            softmax  = tf.one_hot(argmax, ops.num_of_ops, dtype=cfg['datatype'])\n",
    "        #in the train mask = saturated softmax for all ops. in test change it to onehot(hardmax)\n",
    "        \n",
    "        #######################\n",
    "        #perform op selection #\n",
    "        #######################\n",
    "        \n",
    "        #perform all ops in the current timestep intput and save output results together with the op name\n",
    "\n",
    "        op_res = []\n",
    "        for op in ops.ops:\n",
    "            name = op.__name__\n",
    "            op_outp = op(current_input)\n",
    "            op_res.append((name, op_outp))\n",
    "        \n",
    "        #slice softmax results for each operation\n",
    "        ops_softmax = []\n",
    "        for i, op in enumerate(ops.ops):\n",
    "            name = \"slice_\"+op.__name__+\"_softmax_val\"\n",
    "            softmax_slice = tf.slice(softmax, [0,i], [cfg['batch_size'],1], name=name)\n",
    "            ops_softmax.append(softmax_slice)\n",
    "\n",
    "         \n",
    "        #apply softmax on each operation so that operation selection is performed\n",
    "        ops_final = []\n",
    "        for i,res in enumerate(op_res):\n",
    "            name = \"mult_\"+res[0]+\"_softmax\"\n",
    "            op_selection =  tf.multiply(res[1], ops_softmax[i], name=name)\n",
    "            ops_final.append(op_selection)\n",
    "       \n",
    "        #add results from all operation with applied softmax together\n",
    "        output = tf.add_n(ops_final)\n",
    "        \n",
    "        #save the sequance of softmaxes and outputs\n",
    "        outputs.append(output)\n",
    "        softmaxes.append(softmax)\n",
    "    #printtf = tf.Print(output, [output], message=\"Finished cycle\")\n",
    "    #output = tf.reshape( printtf, [batch_size, -1], name = \"dummu_rehap\")\n",
    "    return output, current_state, softmax, outputs, softmaxes\n",
    "\n",
    "#cost function\n",
    "def calc_loss(output):\n",
    "    #reduced_output = tf.reshape( tf.reduce_sum(output, axis = 1, name=\"red_output\"), [batch_size, -1], name=\"resh_red_output\")\n",
    "    math_error = tf.multiply(tf.constant(0.5, dtype=cfg['datatype']), tf.square(tf.subtract(output , batchY_placeholder, name=\"sub_otput_batchY\"), name=\"squar_error\"), name=\"mult_with_0.5\")\n",
    "    \n",
    "    total_loss = tf.reduce_sum(math_error, name=\"red_total_loss\")\n",
    "    return total_loss, math_error\n",
    "\n",
    "output_train, current_state_train, softmax_train, outputs_train, softmaxes_train = run_forward_pass(mode = \"train\")\n",
    "total_loss_train, math_error_train = calc_loss(output_train)\n",
    "\n",
    "output_test, current_state_test, softmax_test, outputs_test, softmaxes_test = run_forward_pass(mode = \"test\")\n",
    "total_loss_test, math_error_test = calc_loss(output_test)\n",
    "\n",
    "grads_raw = tf.gradients(total_loss_train, [W,b,W2,b2], name=\"comp_gradients\")\n",
    "\n",
    "#clip gradients by value and add summaries\n",
    "if cfg['norm']:\n",
    "    print(\"norming the grads\")\n",
    "    grads, norms = tf.clip_by_global_norm(grads_raw, cfg['grad_norm'])\n",
    "    variable_summaries(norms)\n",
    "else:\n",
    "    grads = grads_raw\n",
    "\n",
    "for grad in grads: variable_summaries(grad)\n",
    "\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(cfg['learning_rate'], cfg['epsilon'] ,name=\"AdamOpt\").apply_gradients(zip(grads, [W,b,W2,b2]), name=\"min_loss\")\n",
    "print(\"grads are\")\n",
    "print(grads)\n",
    "\n",
    "#pre training setting\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "#train_fn = np_mult\n",
    "#train_fn = np_stall\n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], cfg['seed'])\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "num_batches = x_train.shape[0]//cfg['batch_size']\n",
    "num_test_batches = x_test.shape[0]//cfg['batch_size']\n",
    "print(\"num batches train:\", num_batches)\n",
    "print(\"num batches test:\", num_test_batches)\n",
    "#model training\n",
    "\n",
    "#create a saver to save the trained model\n",
    "saver=tf.train.Saver(var_list=tf.trainable_variables())\n",
    "\n",
    "#Enable jit\n",
    "config = tf.ConfigProto()\n",
    "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "#define congergance check list\n",
    "last_train_losses = []\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    # Merge all the summaries and write them out \n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('./summaries/' + cfg['dst'] ,sess.graph)\n",
    "    ##enable debugger if necessary\n",
    "    if (cfg['debug']):\n",
    "        print(\"Running in a debug mode\")\n",
    "        sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "        sess.add_tensor_filter(\"has_inf_or_nan\", tf_debug.has_inf_or_nan)\n",
    "\n",
    "    #init the var\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    path = './summaries/np_add-5ops/test7/model/'\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(path))\n",
    "    #plt.ion()\n",
    "    #plt.figure()\n",
    "    #plt.show() \n",
    "    #Init vars:\n",
    "    #_W = sess.run([W])\n",
    "    #_W2 = sess.run([W2])\n",
    "    #print(W.eval())\n",
    "    #print(W2.eval())\n",
    "    globalstartTime = time.time()\n",
    "        \n",
    "    #get soft and hardmaxes out of the model for the last batches\n",
    "    _current_state_train = np.zeros((cfg['batch_size'], cfg['state_size']))\n",
    "    _current_state_test = np.zeros((cfg['batch_size'], cfg['state_size']))\n",
    "\n",
    "        #backprop and test training set for softmax and hardmax loss\n",
    "    for batch_idx in range(num_batches):\n",
    "            start_idx = cfg['batch_size'] * batch_idx\n",
    "            end_idx   = cfg['batch_size'] * batch_idx + cfg['batch_size']\n",
    "\n",
    "            batchX = x_train[start_idx:end_idx]\n",
    "            batchY = y_train[start_idx:end_idx]\n",
    "\n",
    "            #for testing cylce, do one forward and back prop with 1 batch with training data, plus produce summary and hardmax result\n",
    "            _softmaxes_train, _softmax_train = sess.run([softmaxes_train, softmax_train],\n",
    "            feed_dict={\n",
    "                init_state:_current_state_train,\n",
    "                batchX_placeholder:batchX,\n",
    "                batchY_placeholder:batchY\n",
    "            })\n",
    "            \n",
    "            _softmaxes_test, _softmax_test = sess.run([softmaxes_test, softmax_test],\n",
    "                feed_dict={\n",
    "                    init_state:_current_state_test,\n",
    "                    batchX_placeholder:batchX,\n",
    "                    batchY_placeholder:batchY\n",
    "                }) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "[[ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.991  0.     0.009]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.985  0.     0.015]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.964  0.     0.036]\n",
      " [ 0.997  0.     0.003]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.943  0.     0.057]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.996  0.     0.004]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.996  0.     0.004]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.998  0.     0.002]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.998  0.     0.002]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.995  0.     0.005]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.994  0.     0.006]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.796  0.     0.204]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.997  0.     0.003]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]]\n",
      "#####################################################################\n",
      "[[ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.371  0.     0.629]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.783  0.     0.217]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.163  0.     0.837]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.412  0.     0.588]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.14   0.     0.86 ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.567  0.     0.433]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.378  0.     0.622]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.938  0.     0.062]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.984  0.     0.016]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.012  0.     0.988]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.979  0.     0.021]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.983  0.     0.017]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.316  0.     0.684]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 1.     0.     0.   ]\n",
      " [ 0.999  0.     0.001]\n",
      " [ 0.978  0.     0.022]\n",
      " [ 1.     0.     0.   ]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "for softmaxe in _softmaxes_train:\n",
    "    print(\"#####################################################################\")\n",
    "    print(softmaxe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n",
      "#####################################################################\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "for softma in _softmaxes_test:\n",
    "    print(\"#####################################################################\")\n",
    "    print(softma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_softmax_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(50), Dimension(3)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(53), Dimension(50)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(50)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(50)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
