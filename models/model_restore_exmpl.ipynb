{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norming the grads\n",
      "grads are\n",
      "[(<tf.Tensor 'RNN_mem/clip_by_global_norm/RNN_mem/clip_by_global_norm/_0:0' shape=(204, 200) dtype=float64>, <tf.Variable 'W_mem:0' shape=(204, 200) dtype=float64_ref>), (<tf.Tensor 'RNN_mem/clip_by_global_norm/RNN_mem/clip_by_global_norm/_1:0' shape=(200,) dtype=float64>, <tf.Variable 'RNN_mem/Params/b_mem:0' shape=(200,) dtype=float64_ref>), (<tf.Tensor 'RNN_mem/clip_by_global_norm/RNN_mem/clip_by_global_norm/_2:0' shape=(200, 4) dtype=float64>, <tf.Variable 'W2_mem:0' shape=(200, 4) dtype=float64_ref>), (<tf.Tensor 'RNN_mem/clip_by_global_norm/RNN_mem/clip_by_global_norm/_3:0' shape=(4,) dtype=float64>, <tf.Variable 'RNN_mem/Params/b2_mem:0' shape=(4,) dtype=float64_ref>), (<tf.Tensor 'RNN_mem/clip_by_global_norm/RNN_mem/clip_by_global_norm/_4:0' shape=(4, 4) dtype=float64>, <tf.Variable 'W3_mem:0' shape=(4, 4) dtype=float64_ref>), (<tf.Tensor 'RNN_mem/clip_by_global_norm/RNN_mem/clip_by_global_norm/_5:0' shape=(4,) dtype=float64>, <tf.Variable 'RNN_mem/Params/b3_mem:0' shape=(4,) dtype=float64_ref>)]\n",
      "norming the grads\n",
      "grads are\n",
      "[(<tf.Tensor 'RNN_op/clip_by_global_norm/RNN_op/clip_by_global_norm/_0:0' shape=(204, 200) dtype=float64>, <tf.Variable 'W:0' shape=(204, 200) dtype=float64_ref>), (<tf.Tensor 'RNN_op/clip_by_global_norm/RNN_op/clip_by_global_norm/_1:0' shape=(200,) dtype=float64>, <tf.Variable 'RNN_op/Params/b:0' shape=(200,) dtype=float64_ref>), (<tf.Tensor 'RNN_op/clip_by_global_norm/RNN_op/clip_by_global_norm/_2:0' shape=(200, 5) dtype=float64>, <tf.Variable 'W2:0' shape=(200, 5) dtype=float64_ref>), (<tf.Tensor 'RNN_op/clip_by_global_norm/RNN_op/clip_by_global_norm/_3:0' shape=(5,) dtype=float64>, <tf.Variable 'RNN_op/Params/b2:0' shape=(5,) dtype=float64_ref>), (<tf.Tensor 'RNN_op/clip_by_global_norm/RNN_op/clip_by_global_norm/_4:0' shape=(4, 4) dtype=float64>, <tf.Variable 'W3:0' shape=(4, 4) dtype=float64_ref>), (<tf.Tensor 'RNN_op/clip_by_global_norm/RNN_op/clip_by_global_norm/_5:0' shape=(4,) dtype=float64>, <tf.Variable 'RNN_op/Params/b3:0' shape=(4,) dtype=float64_ref>)]\n",
      "writing grad W_0_grad\n",
      "writing grad RNN_op/Params/b_0_grad\n",
      "writing grad W2_0_grad\n",
      "writing grad RNN_op/Params/b2_0_grad\n",
      "writing grad W3_0_grad\n",
      "writing grad RNN_op/Params/b3_0_grad\n",
      "num batches train: 1\n",
      "num batches test: 1\n",
      "INFO:tensorflow:Restoring parameters from /home/user/projects/neural_program_synthesis/models/summaries/1sample/RLRNN/np_center-5ops/total_num_epochs#80000~state_size#200~test_ratio#0.5~num_samples#2~batch_size#1~learning_rate#0.005~epsilon#0.001~num_features#4~state_fn#relu~pen_sofmax#False~augument_grad#False~max_reward#1000~relaunch#True~seed#53375/model/-58745\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from params import get_cfg\n",
    "from rnn_base import RNN\n",
    "from mem_sel_rnn import MemRNN\n",
    "from NoEmbedRNN import OpSel\n",
    "from NoEmbedRNN import MemSel\n",
    "from NoEmbedRNN import RNN as oldRNN\n",
    "from NoEmbedRNN import MemRNN  as oldMemRNN\n",
    "from NoEmbedRNN import HistoryRNN\n",
    "from rl_rnn import RLRNN\n",
    "from rl_rnn_mem import RLRNNMEM\n",
    "from ops import Operations\n",
    "from session import *\n",
    "from data_gen import *\n",
    "import pickle\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "path = \"/home/user/projects/neural_program_synthesis/models/summaries/1sample/RLRNN/np_center-5ops/total_num_epochs#80000~state_size#200~test_ratio#0.5~num_samples#2~batch_size#1~learning_rate#0.005~epsilon#0.001~num_features#4~state_fn#relu~pen_sofmax#False~augument_grad#False~max_reward#1000~relaunch#True~seed#53375\"\n",
    "test_1000 = False\n",
    "old = False\n",
    "\n",
    "model_path = path+'/model'\n",
    "cfg_path = path+'/cfg.p'\n",
    "\n",
    "#get the global configuration\n",
    "cfg = pickle.load(open(cfg_path, 'rb'))\n",
    "\n",
    "\n",
    "#generate data \n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], cfg['seed'])\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "\n",
    "if cfg['model'] == \"RNN\":\n",
    "        ops = Operations(cfg)\n",
    "        if 'used_ops_obj' in cfg:\n",
    "                ops.ops = cfg[\"used_ops_obj\"]\n",
    "                ops.num_of_ops = len(ops.ops)\n",
    "        if 'used_ops_obj_mem' in cfg:\n",
    "                ops.ops_mem = cfg[\"used_ops_obj_mem\"]\n",
    "                ops.num_of_ops_mem = len(ops.ops_mem)\n",
    "        #instantiante the mem selection RNN\n",
    "        if old: mem = oldMemRNN(cfg, ops)\n",
    "        else:   mem = MemRNN(cfg, ops)\n",
    "        # instanitae the model graph with the main OP selection RNN\n",
    "        if old: model = oldRNN(cfg, ops, mem)\n",
    "        else:   model = RNN(cfg, ops, mem)\n",
    "        res = restore_selection_matrixes2RNNS(model, cfg, x_train, x_test, y_train, y_test, model_path, test_1000)\n",
    "elif cfg['model'] == \"HistoryRNN\":\n",
    "        ops = Operations(cfg)\n",
    "        ops.ops = cfg[\"used_ops_obj\"]\n",
    "        ops.num_of_ops = len(ops.ops)\n",
    "        #instantiante the mem and op selection\n",
    "        mem_sel = MemSel(cfg, ops)\n",
    "        op_sel = OpSel(cfg, ops)\n",
    "        # instanitae the model graph with the main OP selection RNN\n",
    "        model = HistoryRNN(cfg, ops, mem_sel, op_sel)\n",
    "        res = restore_selection_matrixes_HistoryRNNS(model, cfg, x_train, x_test, y_train, y_test, model_path, test_1000)\n",
    "elif cfg['model'] == \"RLRNN\":\n",
    "        ops_env = OpsEnv(cfg)\n",
    "        if 'used_ops_env' in cfg:\n",
    "                ops_env = cfg[\"used_ops_env\"]\n",
    "        mem = RLRNNMEM(cfg, ops_env) \n",
    "        model = RLRNN(cfg, ops_env, mem) \n",
    "        res = restore_selection_RL_RNN(model, cfg, x_train, x_test, y_train, y_test, model_path, test_1000)\n",
    "else:\n",
    "        raise Exception('did not find the model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_errors(error_lst, name):\n",
    "    print(\"\")\n",
    "    print(\"Total\", reduce((lambda x, y: x + y), error_lst))\n",
    "    for i, error in enumerate(error_lst):\n",
    "        print(name + \"[\" + str(i) + \"] err is \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_matrix(total_error, matrix_lst, indeces = None):\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(\"Error for this matrix is\", total_error)\n",
    "    for elem in range(len(matrix_lst[0])):\n",
    "        if indeces is not None and elem not in indeces: continue \n",
    "        print(\"\\n##Elem-\"+str(elem)+\"--#############################################################\")        \n",
    "        for matrix in matrix_lst:\n",
    "            print(matrix[elem], end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_ops_matrix(total_error, matrix_lst, ops_list, indeces = None):\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(\"Error for this matrix is\", total_error)\n",
    "    for elem in range(len(matrix_lst[0])):\n",
    "        if indeces is not None and elem not in indeces: continue \n",
    "        print(\"\\n##Elem-\"+str(elem)+\"--#############################################################\")        \n",
    "        for matrix in matrix_lst:\n",
    "            index = np.argmax(matrix[elem])\n",
    "            if len(matrix[elem]) < 2:\n",
    "                index = matrix[elem][0]\n",
    "            op_name = ops_list[index].__name__\n",
    "            print(\"[ \"+op_name+\" ]\", end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total 220.939952266\n",
      "train_math_error[0] err is 220.939952266\n",
      "\n",
      "Total 0.0\n",
      "test_math_error[0] err is 0.0\n"
     ]
    }
   ],
   "source": [
    "#print_errors(res[\"total_loss_traind_train\"], \"sofmax_train_error\")\n",
    "#print_errors(res[\"total_loss_traind_test\"], \"hardmax_train_error\")\n",
    "#print_errors(res[\"total_loss_testd_train\"], \"softmax_test_error\")\n",
    "#print_errors(res[\"total_loss_testd_test\"], \"hardmax_test_error\")\n",
    "\n",
    "print_errors(res[\"train_math_error\"], \"train_math_error\")\n",
    "print_errors(res[\"test_math_error\"], \"test_math_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for this matrix is 0.0\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[4] [4] [3] [4] \n",
      "Error for this matrix is 0.0\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[ np_sub_env ] [ np_sub_env ] [ np_div_env ] [ np_sub_env ] \n"
     ]
    }
   ],
   "source": [
    "#Softmax Hardmax Print\n",
    "#print_matrix(res[\"total_loss_traind_train\"][0], res[\"softmaxes_traind_train\"][0])\n",
    "#print_ops_matrix(res[\"total_loss_traind_train\"][0], res[\"softmaxes_traind_train\"][0], cfg[\"used_ops_obj\"])\n",
    "\n",
    "##RL print - train OP selections\n",
    "print_matrix(res[\"test_math_error\"][0], res[\"test_selections\"][0])\n",
    "print_ops_matrix(res[\"test_math_error\"][0], res[\"test_selections\"][0], cfg[\"used_ops_env\"].ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for this matrix is 0.0\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[3] [0] [2] [3] \n",
      "Error for this matrix is 0.0\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[ np_stall_env ] [ np_add_env ] [ np_get_size_env ] [ np_stall_env ] \n"
     ]
    }
   ],
   "source": [
    "#Softmax Hardmax Print\n",
    "\n",
    "#print_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test\"][0])\n",
    "#print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test\"][0], cfg[\"used_ops_obj\"])\n",
    "\n",
    "##RL print - train MEM selections\n",
    "print_matrix(res[\"test_math_error\"][0], res[\"test_selections_mem\"][0])\n",
    "print_ops_matrix(res[\"test_math_error\"][0], res[\"test_selections_mem\"][0], cfg[\"used_ops_env\"].ops_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 29.089, -88.536,  20.493, -94.298]]),\n",
       "  array([[ 447.356,  -59.463,  -49.153,  103.597]]),\n",
       "  array([[ 421.424,  469.706, -568.444,  621.959]]),\n",
       "  array([[-1739.944,  1072.938,  -587.89 ,    41.647]])]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['test_current_exes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[   0.   , -117.625,   -8.596, -123.387]]),\n",
       "  array([[-133.251,    0.   ,    0.   ,    0.   ]]),\n",
       "  array([[-33.313,   0.   ,   0.   ,   0.   ]]),\n",
       "  array([[ 62.402, -55.223,  53.806, -60.985]])]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['test_outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 29.089, -88.536,  20.493, -94.298]]),\n",
       "  array([[-133.251,    0.   ,    0.   ,    0.   ]]),\n",
       "  array([[4, 0, 0, 0]]),\n",
       "  array([[ 29.089, -88.536,  20.493, -94.298]])]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['test_outputs_mem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 62.402, -55.223,  53.806, -60.985]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['batchesY_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 29.089, -88.536,  20.493, -94.298]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['batchesX_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batchesY_train', 'test_selections_mem', 'train_states', 'train_current_exes', 'test_outputs_mem', 'test_selections', 'test_outputs', 'train_states_mem', 'batchesX_train', 'batchesY_test', 'train_selections', 'test_rewards', 'batchesX_test', 'test_current_exes_mem', 'train_selections_mem', 'test_states', 'train_rewards', 'test_discount_rewards', 'test_math_error', 'test_states_mem', 'train_math_error', 'test_current_exes', 'train_outputs', 'train_current_exes_mem', 'train_discount_rewards', 'train_outputs_mem'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for this matrix is 2.52435489671e-29\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[ 1.  0.  0.  0.] [ 1.  0.  0.  0.] [ 0.  0.  1.  0.] [ 0.  0.  1.  0.] [ 0.  0.  1.  0.] \n",
      "Error for this matrix is 2.52435489671e-29\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_stall ] [ tf_stall ] [ tf_stall ] \n"
     ]
    }
   ],
   "source": [
    "#Softmax Hardmax Print\n",
    "\n",
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0])\n",
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], ops.ops_mem )\n",
    "\n",
    "##RL print - train MEM selections\n",
    "#print_matrix(res[\"train_math_error\"][0], res[\"train_selections_mem\"][0])\n",
    "#print_ops_matrix(res[\"train_math_error\"][0], res[\"train_selections_mem\"][0], cfg[\"used_ops_env\"].ops_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##RL print - test OP selections\n",
    "print_matrix(res[\"test_math_error\"][0], res[\"test_selections\"][0])\n",
    "print_ops_matrix(res[\"test_math_error\"][0], res[\"test_selections\"][0], cfg[\"used_ops_env\"].ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##RL print - test MEM selections\n",
    "print_matrix(res[\"test_math_error\"][0], res[\"test_selections_mem\"][0])\n",
    "print_ops_matrix(res[\"test_math_error\"][0], res[\"test_selections_mem\"][0], cfg[\"used_ops_env\"].ops_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"outputs_testd_train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_res = np.nonzero(np.round(np.apply_along_axis(np_add, 1, res[\"outputs_testd_train\"][0][4] - res[\"batchesY_test\"][0]), 2))[0]\n",
    "wrong_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test\"][0], cfg[\"used_ops_obj\"], wrong_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"], wrong_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_matrix(res[\"total_loss_traind_train\"][1], res[\"softmaxes_traind_train_mem\"][1])\n",
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"outputs_testd_test_mem\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res['last_hardmax_state_train_mem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg['num_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 10000\n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], seed)\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "#res_pred = predict_form_sess(model, cfg, x_test[0:100,], res['last_hardmax_state_train'],res['last_hardmax_state_train_mem'], path = model_path, mode=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test[0:100,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(res[\"softmaxes_traind_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1000_samples_RL(model, res['sess'],92964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res['test_discount_rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
