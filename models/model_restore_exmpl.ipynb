{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "[<tf.Variable 'W_mem:0' shape=(104, 100) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/b_mem:0' shape=(100,) dtype=float64_ref>, <tf.Variable 'W2_mem:0' shape=(100, 4) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/b2_mem:0' shape=(4,) dtype=float64_ref>, <tf.Variable 'W:0' shape=(104, 100) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/b:0' shape=(100,) dtype=float64_ref>, <tf.Variable 'W2:0' shape=(100, 6) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/b2:0' shape=(6,) dtype=float64_ref>, <tf.Variable 'W3:0' shape=(6, 4) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/b3:0' shape=(4,) dtype=float64_ref>]\n",
      "norming the grads\n",
      "grads are\n",
      "[(<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_0:0' shape=(104, 100) dtype=float64>, <tf.Variable 'W_mem:0' shape=(104, 100) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_1:0' shape=(100,) dtype=float64>, <tf.Variable 'RNN_mem/Params/b_mem:0' shape=(100,) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_2:0' shape=(100, 4) dtype=float64>, <tf.Variable 'W2_mem:0' shape=(100, 4) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_3:0' shape=(4,) dtype=float64>, <tf.Variable 'RNN_mem/Params/b2_mem:0' shape=(4,) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_4:0' shape=(104, 100) dtype=float64>, <tf.Variable 'W:0' shape=(104, 100) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_5:0' shape=(100,) dtype=float64>, <tf.Variable 'RNN_op/Params/b:0' shape=(100,) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_6:0' shape=(100, 6) dtype=float64>, <tf.Variable 'W2:0' shape=(100, 6) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_7:0' shape=(6,) dtype=float64>, <tf.Variable 'RNN_op/Params/b2:0' shape=(6,) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_8:0' shape=(6, 4) dtype=float64>, <tf.Variable 'W3:0' shape=(6, 4) dtype=float64_ref>), (<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_9:0' shape=(4,) dtype=float64>, <tf.Variable 'RNN_op/Params/b3:0' shape=(4,) dtype=float64_ref>)]\n",
      "norm is \n",
      "Tensor(\"RNN_op/Grads/global_norm/global_norm:0\", shape=(), dtype=float64)\n",
      "writing grad W_mem_0_grad\n",
      "writing grad RNN_mem/Params/b_mem_0_grad\n",
      "writing grad W2_mem_0_grad\n",
      "writing grad RNN_mem/Params/b2_mem_0_grad\n",
      "writing grad W_0_grad\n",
      "writing grad RNN_op/Params/b_0_grad\n",
      "writing grad W2_0_grad\n",
      "writing grad RNN_op/Params/b2_0_grad\n",
      "writing grad W3_0_grad\n",
      "writing grad RNN_op/Params/b3_0_grad\n",
      "num batches train: 10\n",
      "num batches test: 4\n",
      "INFO:tensorflow:Restoring parameters from /home/user/neural_program_synthesis/models/summaries/RNN/np_add-5ops/state_size_100-num_samples_1500-batch_size_100-test_ratio_0.33-learning_rate_0.005-epsilon_0.001-num_features_4-norm_True-softmax_sat_100-state_fn_relu-smax_pen_r_0.0-total_num_epochs_40000-augument_grad_True-relaunch_True-seed_52444//model/-10\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from params import get_cfg\n",
    "from rnn_base import RNN\n",
    "from mem_sel_rnn import MemRNN\n",
    "from NoEmbedRNN import OpSel\n",
    "from NoEmbedRNN import MemSel\n",
    "from NoEmbedRNN import RNN as oldRNN\n",
    "from NoEmbedRNN import MemRNN  as oldMemRNN\n",
    "from NoEmbedRNN import HistoryRNN\n",
    "from rl_rnn import RLRNN\n",
    "from rl_rnn_mem import RLRNNMEM\n",
    "from ops import Operations\n",
    "from session import *\n",
    "from data_gen import *\n",
    "import pickle\n",
    "from functools import reduce\n",
    "\n",
    "#modelName = 'RLRNN'\n",
    "modelName = 'RNN'\n",
    "old = False\n",
    "func = 'np_add-5ops'\n",
    "name = 'state_size_100-num_samples_1500-batch_size_100-test_ratio_0.33-learning_rate_0.005-epsilon_0.001-num_features_4-norm_True-softmax_sat_100-state_fn_relu-smax_pen_r_0.0-total_num_epochs_40000-augument_grad_True-relaunch_True-seed_52444'\n",
    "path = '/home/user/neural_program_synthesis/models/summaries/'+modelName+'/'+func+'/'+name+'/'\n",
    "model_path = path+'/model'\n",
    "#get the global configuration\n",
    "cfg_path = path+'cfg.p'\n",
    "cfg = pickle.load(open(cfg_path, 'rb'))\n",
    "#instantiate containter with the operations avail for the selection\n",
    "ops = Operations(cfg)\n",
    "ops.ops = cfg[\"used_ops_obj\"]\n",
    "ops.num_of_ops = len(ops.ops)\n",
    "#generate data \n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], cfg['seed'])\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "\n",
    "if modelName == \"RNN\":\n",
    "        #instantiante the mem selection RNN\n",
    "        if old: mem = oldMemRNN(cfg, ops)\n",
    "        else:   mem = MemRNN(cfg, ops)\n",
    "        # instanitae the model graph with the main OP selection RNN\n",
    "        if old: model = oldRNN(cfg, ops, mem)\n",
    "        else:   model = RNN(cfg, ops, mem)\n",
    "        res = restore_selection_matrixes2RNNS(model, cfg, x_train, x_test, y_train, y_test, model_path)\n",
    "elif modelName == \"HistoryRNN\":\n",
    "        #instantiante the mem and op selection\n",
    "        mem_sel = MemSel(cfg, ops)\n",
    "        op_sel = OpSel(cfg, ops)\n",
    "        # instanitae the model graph with the main OP selection RNN\n",
    "        model = HistoryRNN(cfg, ops, mem_sel, op_sel)\n",
    "        res = restore_selection_matrixes_HistoryRNNS(model, cfg, x_train, x_test, y_train, y_test, model_path)\n",
    "elif modelName == \"RLRNN\":\n",
    "        ops_env = cfg[\"used_ops_env\"]\n",
    "        mem = RLRNNMEM(cfg, ops_env) \n",
    "        model = RLRNN(cfg, ops_env, mem) \n",
    "        res = restore_selection_RL_RNN(model, cfg, x_train, x_test, y_train, y_test, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_errors(error_lst, name):\n",
    "    print(\"\")\n",
    "    print(\"Total\", reduce((lambda x, y: x + y), error_lst))\n",
    "    for i, error in enumerate(error_lst):\n",
    "        print(name + \"[\" + str(i) + \"] err is \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_matrix(total_error, matrix_lst, indeces = None):\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(\"Error for this matrix is\", total_error)\n",
    "    for elem in range(len(matrix_lst[0])):\n",
    "        if indeces is not None and elem not in indeces: continue \n",
    "        print(\"\\n##Elem-\"+str(elem)+\"--#############################################################\")        \n",
    "        for matrix in matrix_lst:\n",
    "            print(matrix[elem], end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_ops_matrix(total_error, matrix_lst, ops_list, indeces = None):\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(\"Error for this matrix is\", total_error)\n",
    "    for elem in range(len(matrix_lst[0])):\n",
    "        if indeces is not None and elem not in indeces: continue \n",
    "        print(\"\\n##Elem-\"+str(elem)+\"--#############################################################\")        \n",
    "        for matrix in matrix_lst:\n",
    "            index = np.argmax(matrix[elem])\n",
    "            if len(matrix[elem]) < 2:\n",
    "                index = matrix[elem][0]\n",
    "            op_name = ops_list[index].__name__\n",
    "            print(\"[ \"+op_name+\" ]\", end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_errors(res[\"total_loss_traind_train\"], \"sofmax_train_error\")\n",
    "print_errors(res[\"total_loss_traind_test\"], \"hardmax_train_error\")\n",
    "print_errors(res[\"total_loss_testd_train\"], \"softmax_test_error\")\n",
    "print_errors(res[\"total_loss_testd_test\"], \"hardmax_test_error\")\n",
    "\n",
    "#print_errors(res[\"train_math_error\"], \"train_math_error\")\n",
    "#print_errors(res[\"test_math_error\"], \"test_math_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Softmax Hardmax Print\n",
    "print_matrix(res[\"total_loss_traind_train\"][0], res[\"softmaxes_traind_train\"][0])\n",
    "print_ops_matrix(res[\"total_loss_traind_train\"][0], res[\"softmaxes_traind_train\"][0], cfg[\"used_ops_obj\"])\n",
    "\n",
    "##RL print - train OP selections\n",
    "#print_matrix(res[\"train_math_error\"][0], res[\"train_selections\"][0])\n",
    "#print_ops_matrix(res[\"train_math_error\"][0], res[\"train_selections\"][0], cfg[\"used_ops_env\"].ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Softmax Hardmax Print\n",
    "\n",
    "#print_matrix(res[\"total_loss_traind_test\"][1], res[\"softmaxes_traind_test\"][1])\n",
    "#print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"])\n",
    "\n",
    "##RL print - train MEM selections\n",
    "print_matrix(res[\"train_math_error\"][0], res[\"train_selections_mem\"][0])\n",
    "print_ops_matrix(res[\"train_math_error\"][0], res[\"train_selections_mem\"][0], cfg[\"used_ops_env\"].ops_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##RL print - test OP selections\n",
    "print_matrix(res[\"test_math_error\"][0], res[\"test_selections\"][0])\n",
    "print_ops_matrix(res[\"test_math_error\"][0], res[\"test_selections\"][0], cfg[\"used_ops_env\"].ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##RL print - test MEM selections\n",
    "print_matrix(res[\"test_math_error\"][0], res[\"test_selections_mem\"][0])\n",
    "print_ops_matrix(res[\"test_math_error\"][0], res[\"test_selections_mem\"][0], cfg[\"used_ops_env\"].ops_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"outputs_testd_train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wrong_res = np.nonzero(np.round(np.apply_along_axis(np_add, 1, res[\"outputs_testd_train\"][0][4] - res[\"batchesY_test\"][0]), 2))[0]\n",
    "wrong_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test\"][0], cfg[\"used_ops_obj\"], wrong_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"], wrong_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print_matrix(res[\"total_loss_traind_train\"][1], res[\"softmaxes_traind_train_mem\"][1])\n",
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"outputs_testd_test_mem\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res['last_hardmax_state_train_mem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cfg['num_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 10000\n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], seed)\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "#res_pred = predict_form_sess(model, cfg, x_test[0:100,], res['last_hardmax_state_train'],res['last_hardmax_state_train_mem'], path = model_path, mode=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.09403021, -65.62693699,  70.5863619 , -63.95531784]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test[0:100,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(res[\"softmaxes_traind_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
