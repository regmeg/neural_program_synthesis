{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "timestep 0\n",
      "timestep 1\n",
      "timestep 2\n",
      "timestep 3\n",
      "timestep 4\n",
      "[<tf.Variable 'RNN_mem/Params/W_mem:0' shape=(304, 300) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/b_mem:0' shape=(300,) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/W2_mem:0' shape=(300, 5) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/b2_mem:0' shape=(5,) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/W3_mem:0' shape=(5, 4) dtype=float64_ref>, <tf.Variable 'RNN_mem/Params/b3_mem:0' shape=(4,) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/W:0' shape=(304, 300) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/b:0' shape=(300,) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/W2:0' shape=(300, 5) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/b2:0' shape=(5,) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/W3:0' shape=(5, 4) dtype=float64_ref>, <tf.Variable 'RNN_op/Params/b3:0' shape=(4,) dtype=float64_ref>]\n",
      "norming the grads\n",
      "grads are\n",
      "[<tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_0:0' shape=(304, 300) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_1:0' shape=(300,) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_2:0' shape=(300, 5) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_3:0' shape=(5,) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_4:0' shape=(5, 4) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_5:0' shape=(4,) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_6:0' shape=(304, 300) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_7:0' shape=(300,) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_8:0' shape=(300, 5) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_9:0' shape=(5,) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_10:0' shape=(5, 4) dtype=float64>, <tf.Tensor 'RNN_op/Grads/clip_by_global_norm/RNN_op/Grads/clip_by_global_norm/_11:0' shape=(4,) dtype=float64>]\n",
      "norm is \n",
      "Tensor(\"RNN_op/Grads/global_norm/global_norm:0\", shape=(), dtype=float64)\n",
      "num batches train: 23\n",
      "num batches test: 11\n",
      "INFO:tensorflow:Restoring parameters from /home/user/projects/neural_program_synthesis/models/summaries/RNN/np_avg_val-5ops/one_both_hardmaxes_have_sat_sat_grad_out/state_size_300-num_samples_3500-batch_size_100-learning_rate_0.001-epsilon_0.001-num_features_4-norm_True-softmax_sat_800-clip_False-share_state_True-rnns_same_state_False-state_fn_relu-pen_sofmax_True-smax_pen_r_0-seed_94169//model/-510\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from params import get_cfg\n",
    "from rnn_base import RNN\n",
    "from mem_sel_rnn import MemRNN\n",
    "from NoEmbedRNN import OpSel\n",
    "from NoEmbedRNN import MemSel\n",
    "from NoEmbedRNN import RNN as oldRNN\n",
    "from NoEmbedRNN import MemRNN  as oldMemRNN\n",
    "from NoEmbedRNN import HistoryRNN\n",
    "from ops import Operations\n",
    "from session import *\n",
    "from data_gen import *\n",
    "import pickle\n",
    "from functools import reduce\n",
    "\n",
    "modelName = 'RNN'\n",
    "old = False\n",
    "func = 'np_avg_val-5ops'\n",
    "name = 'one_both_hardmaxes_have_sat_sat_grad_out/state_size_300-num_samples_3500-batch_size_100-learning_rate_0.001-epsilon_0.001-num_features_4-norm_True-softmax_sat_800-clip_False-share_state_True-rnns_same_state_False-state_fn_relu-pen_sofmax_True-smax_pen_r_0-seed_94169'\n",
    "path = '/home/user/projects/neural_program_synthesis/models/summaries/'+modelName+'/'+func+'/'+name+'/'\n",
    "model_path = path+'/model'\n",
    "#get the global configuration\n",
    "cfg_path = path+'cfg.p'\n",
    "cfg = pickle.load(open(cfg_path, 'rb'))\n",
    "#instantiate containter with the operations avail for the selection\n",
    "ops = Operations(cfg)\n",
    "ops.ops = cfg[\"used_ops_obj\"]\n",
    "ops.num_of_ops = len(ops.ops)\n",
    "#generate data \n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], cfg['seed'])\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "\n",
    "if modelName == \"RNN\":\n",
    "        #instantiante the mem selection RNN\n",
    "        if old: mem = oldMemRNN(cfg, ops)\n",
    "        else:   mem = MemRNN(cfg, ops)\n",
    "        # instanitae the model graph with the main OP selection RNN\n",
    "        if old: model = oldRNN(cfg, ops, mem)\n",
    "        else:   model = RNN(cfg, ops, mem)\n",
    "        res = restore_selection_matrixes2RNNS(model, cfg, x_train, x_test, y_train, y_test, model_path)\n",
    "elif modelName == \"HistoryRNN\":\n",
    "        #instantiante the mem and op selection\n",
    "        mem_sel = MemSel(cfg, ops)\n",
    "        op_sel = OpSel(cfg, ops)\n",
    "        # instanitae the model graph with the main OP selection RNN\n",
    "        model = HistoryRNN(cfg, ops, mem_sel, op_sel)\n",
    "        res = restore_selection_matrixes_HistoryRNNS(model, cfg, x_train, x_test, y_train, y_test, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_errors(error_lst, name):\n",
    "    print(\"\")\n",
    "    print(\"Total\", reduce((lambda x, y: x + y), error_lst))\n",
    "    for i, error in enumerate(error_lst):\n",
    "        print(name + \"[\" + str(i) + \"] err is \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_matrix(total_error, matrix_lst, indeces = None):\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(\"Error for this matrix is\", total_error)\n",
    "    for elem in range(len(matrix_lst[0])):\n",
    "        if indeces is not None and elem not in indeces: continue \n",
    "        print(\"\\n##Elem-\"+str(elem)+\"--#############################################################\")        \n",
    "        for matrix in matrix_lst:\n",
    "            print(matrix[elem], end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_ops_matrix(total_error, matrix_lst, ops_list, indeces = None):\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print(\"Error for this matrix is\", total_error)\n",
    "    for elem in range(len(matrix_lst[0])):\n",
    "        if indeces is not None and elem not in indeces: continue \n",
    "        print(\"\\n##Elem-\"+str(elem)+\"--#############################################################\")        \n",
    "        for matrix in matrix_lst:\n",
    "            index = np.argmax(matrix[elem])\n",
    "            op_name = ops_list[index].__name__\n",
    "            print(\"[ \"+op_name+\" ]\", end=\" \")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_errors(res[\"total_loss_traind_train\"], \"sofmax_train_error\")\n",
    "print_errors(res[\"total_loss_traind_test\"], \"hardmax_train_error\")\n",
    "print_errors(res[\"total_loss_testd_train\"], \"softmax_test_error\")\n",
    "print_errors(res[\"total_loss_testd_test\"], \"hardmax_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for this matrix is 1.45150406561e-28\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-1--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-2--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-3--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-4--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-5--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-6--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-7--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-8--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-9--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-10--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-11--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-12--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-13--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-14--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-15--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-16--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-17--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-18--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-19--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-20--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-21--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-22--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-23--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-24--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-25--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-26--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-27--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-28--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-29--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-30--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-31--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-32--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-33--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-34--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-35--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-36--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-37--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-38--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-39--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-40--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-41--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-42--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-43--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-44--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-45--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-46--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-47--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-48--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-49--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-50--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-51--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-52--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-53--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-54--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-55--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-56--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-57--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-58--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-59--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-60--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-61--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-62--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-63--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-64--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-65--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-66--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-67--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-68--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-69--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-70--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-71--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-72--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-73--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-74--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-75--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-76--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-77--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-78--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-79--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-80--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-81--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-82--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-83--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-84--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-85--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-86--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-87--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-88--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-89--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-90--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-91--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-92--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-93--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-94--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-95--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-96--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-97--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-98--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n",
      "##Elem-99--#############################################################\n",
      "[ tf_add ] [ tf_add ] [ tf_add ] [ tf_divide ] [ tf_add ] \n"
     ]
    }
   ],
   "source": [
    "#print_matrix(res[\"total_loss_traind_train\"][0], res[\"softmaxes_traind_train\"][0])\n",
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test\"][0], cfg[\"used_ops_obj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for this matrix is 1.45150406561e-28\n",
      "\n",
      "##Elem-0--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-1--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-2--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-3--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-4--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-5--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-6--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-7--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-8--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-9--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-10--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-11--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-12--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-13--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-14--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-15--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-16--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-17--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-18--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-19--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-20--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-21--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-22--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-23--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-24--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-25--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-26--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-27--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-28--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-29--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-30--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-31--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-32--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-33--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-34--#############################################################\n",
      "[ tf_add ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-35--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-36--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-37--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-38--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-39--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-40--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-41--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-42--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-43--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-44--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-45--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-46--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-47--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-48--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-49--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-50--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-51--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-52--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-53--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-54--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-55--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-56--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-57--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-58--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-59--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-60--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-61--#############################################################\n",
      "[ tf_add ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-62--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-63--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-64--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-65--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-66--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-67--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-68--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-69--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-70--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-71--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-72--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-73--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-74--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-75--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-76--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-77--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-78--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-79--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-80--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-81--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-82--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-83--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-84--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-85--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-86--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-87--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-88--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-89--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-90--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-91--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-92--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-93--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-94--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-95--#############################################################\n",
      "[ tf_stall ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-96--#############################################################\n",
      "[ tf_divide ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-97--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-98--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n",
      "##Elem-99--#############################################################\n",
      "[ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] [ tf_inpt_len ] \n"
     ]
    }
   ],
   "source": [
    "#print_matrix(res[\"total_loss_traind_test\"][1], res[\"softmaxes_traind_test\"][1])\n",
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"outputs_testd_train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_res = np.nonzero(np.round(np.apply_along_axis(np_add, 1, res[\"outputs_testd_train\"][0][4] - res[\"batchesY_test\"][0]), 2))[0]\n",
    "wrong_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test\"][0], cfg[\"used_ops_obj\"], wrong_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"], wrong_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print_matrix(res[\"total_loss_traind_train\"][1], res[\"softmaxes_traind_train_mem\"][1])\n",
    "print_ops_matrix(res[\"total_loss_testd_test\"][0], res[\"softmaxes_testd_test_mem\"][0], cfg[\"used_ops_obj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_matrix(res[\"total_loss_testd_test\"][0], res[\"outputs_testd_test_mem\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res['last_hardmax_state_train_mem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg['num_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/user/projects/neural_program_synthesis/models/summaries/RNN/np_avg_val-5ops/one_both_hardmaxes_have_sat_sat_grad_out/state_size_300-num_samples_3500-batch_size_100-learning_rate_0.001-epsilon_0.001-num_features_4-norm_True-softmax_sat_800-clip_False-share_state_True-rnns_same_state_False-state_fn_relu-pen_sofmax_True-smax_pen_r_0-seed_94169//model/-510\n"
     ]
    }
   ],
   "source": [
    "seed = 10000\n",
    "x,y = samples_generator(cfg['train_fn'], (cfg['num_samples'], cfg['num_features']) , cfg['samples_value_rng'], seed)\n",
    "x_train, x_test, y_train, y_test = split_train_test (x, y , cfg['test_ratio'])\n",
    "res_pred = predict_form_sess(model, cfg, x_test[0:100,], res['last_hardmax_state_train'],res['last_hardmax_state_train_mem'], path = model_path, mode=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-16.036,   0.   ,   0.   ,   0.   ],\n",
       "        [ 27.502,   0.   ,   0.   ,   0.   ],\n",
       "        [ 52.418,   0.   ,   0.   ,   0.   ],\n",
       "        [-28.386,   0.   ,   0.   ,   0.   ],\n",
       "        [ 46.806,   0.   ,   0.   ,   0.   ],\n",
       "        [-17.814,   0.   ,   0.   ,   0.   ],\n",
       "        [ 31.01 ,   0.   ,   0.   ,   0.   ],\n",
       "        [ 33.416,   0.   ,   0.   ,   0.   ],\n",
       "        [ -3.253,   0.   ,   0.   ,   0.   ],\n",
       "        [ -6.009,   0.   ,   0.   ,   0.   ],\n",
       "        [ 10.124,   0.   ,   0.   ,   0.   ],\n",
       "        [-18.129,   0.   ,   0.   ,   0.   ],\n",
       "        [-15.935,   0.   ,   0.   ,   0.   ],\n",
       "        [-38.142,   0.   ,   0.   ,   0.   ],\n",
       "        [ -2.284,   0.   ,   0.   ,   0.   ],\n",
       "        [ 29.673,   0.   ,   0.   ,   0.   ],\n",
       "        [ 22.864,   0.   ,   0.   ,   0.   ],\n",
       "        [ 32.752,   0.   ,   0.   ,   0.   ],\n",
       "        [-47.395,   0.   ,   0.   ,   0.   ],\n",
       "        [ 10.248,   0.   ,   0.   ,   0.   ],\n",
       "        [ 26.164,   0.   ,   0.   ,   0.   ],\n",
       "        [ 29.636,   0.   ,   0.   ,   0.   ],\n",
       "        [  5.778,   0.   ,   0.   ,   0.   ],\n",
       "        [ -4.698,   0.   ,   0.   ,   0.   ],\n",
       "        [  5.194,   0.   ,   0.   ,   0.   ],\n",
       "        [  9.972,   0.   ,   0.   ,   0.   ],\n",
       "        [ -4.383,   0.   ,   0.   ,   0.   ],\n",
       "        [-62.01 ,   0.   ,   0.   ,   0.   ],\n",
       "        [-44.214,   0.   ,   0.   ,   0.   ],\n",
       "        [ -7.454,   0.   ,   0.   ,   0.   ],\n",
       "        [-51.172,   0.   ,   0.   ,   0.   ],\n",
       "        [-11.557,   0.   ,   0.   ,   0.   ],\n",
       "        [ -5.414,   0.   ,   0.   ,   0.   ],\n",
       "        [  8.475,   0.   ,   0.   ,   0.   ],\n",
       "        [  2.303,   0.   ,   0.   ,   0.   ],\n",
       "        [-18.787,   0.   ,   0.   ,   0.   ],\n",
       "        [ 24.183,   0.   ,   0.   ,   0.   ],\n",
       "        [ 35.508,   0.   ,   0.   ,   0.   ],\n",
       "        [-21.017,   0.   ,   0.   ,   0.   ],\n",
       "        [-19.271,   0.   ,   0.   ,   0.   ],\n",
       "        [ 34.701,   0.   ,   0.   ,   0.   ],\n",
       "        [-24.072,   0.   ,   0.   ,   0.   ],\n",
       "        [-45.005,   0.   ,   0.   ,   0.   ],\n",
       "        [ 46.8  ,   0.   ,   0.   ,   0.   ],\n",
       "        [ 23.924,   0.   ,   0.   ,   0.   ],\n",
       "        [-46.339,   0.   ,   0.   ,   0.   ],\n",
       "        [ 14.97 ,   0.   ,   0.   ,   0.   ],\n",
       "        [ 11.626,   0.   ,   0.   ,   0.   ],\n",
       "        [-23.414,   0.   ,   0.   ,   0.   ],\n",
       "        [-34.974,   0.   ,   0.   ,   0.   ],\n",
       "        [-34.588,   0.   ,   0.   ,   0.   ],\n",
       "        [  1.99 ,   0.   ,   0.   ,   0.   ],\n",
       "        [-26.145,   0.   ,   0.   ,   0.   ],\n",
       "        [  5.932,   0.   ,   0.   ,   0.   ],\n",
       "        [-18.672,   0.   ,   0.   ,   0.   ],\n",
       "        [-27.364,   0.   ,   0.   ,   0.   ],\n",
       "        [-65.71 ,   0.   ,   0.   ,   0.   ],\n",
       "        [ 28.563,   0.   ,   0.   ,   0.   ],\n",
       "        [-25.207,   0.   ,   0.   ,   0.   ],\n",
       "        [ -8.444,   0.   ,   0.   ,   0.   ],\n",
       "        [ 39.028,   0.   ,   0.   ,   0.   ],\n",
       "        [-12.453,   0.   ,   0.   ,   0.   ],\n",
       "        [ -2.357,   0.   ,   0.   ,   0.   ],\n",
       "        [-18.12 ,   0.   ,   0.   ,   0.   ],\n",
       "        [-16.853,   0.   ,   0.   ,   0.   ],\n",
       "        [ 48.721,   0.   ,   0.   ,   0.   ],\n",
       "        [ -2.863,   0.   ,   0.   ,   0.   ],\n",
       "        [-17.931,   0.   ,   0.   ,   0.   ],\n",
       "        [ -7.758,   0.   ,   0.   ,   0.   ],\n",
       "        [-18.089,   0.   ,   0.   ,   0.   ],\n",
       "        [ 12.676,   0.   ,   0.   ,   0.   ],\n",
       "        [-19.02 ,   0.   ,   0.   ,   0.   ],\n",
       "        [-30.729,   0.   ,   0.   ,   0.   ],\n",
       "        [ 47.43 ,   0.   ,   0.   ,   0.   ],\n",
       "        [ 16.115,   0.   ,   0.   ,   0.   ],\n",
       "        [  5.325,   0.   ,   0.   ,   0.   ],\n",
       "        [  8.124,   0.   ,   0.   ,   0.   ],\n",
       "        [-11.511,   0.   ,   0.   ,   0.   ],\n",
       "        [ 30.324,   0.   ,   0.   ,   0.   ],\n",
       "        [ -5.749,   0.   ,   0.   ,   0.   ],\n",
       "        [ -7.857,   0.   ,   0.   ,   0.   ],\n",
       "        [-61.689,   0.   ,   0.   ,   0.   ],\n",
       "        [ 20.852,   0.   ,   0.   ,   0.   ],\n",
       "        [-13.3  ,   0.   ,   0.   ,   0.   ],\n",
       "        [ 18.456,   0.   ,   0.   ,   0.   ],\n",
       "        [ 52.963,   0.   ,   0.   ,   0.   ],\n",
       "        [ -5.041,   0.   ,   0.   ,   0.   ],\n",
       "        [  5.619,   0.   ,   0.   ,   0.   ],\n",
       "        [ 40.855,   0.   ,   0.   ,   0.   ],\n",
       "        [ -8.657,   0.   ,   0.   ,   0.   ],\n",
       "        [-44.672,   0.   ,   0.   ,   0.   ],\n",
       "        [ 11.846,   0.   ,   0.   ,   0.   ],\n",
       "        [-10.876,   0.   ,   0.   ,   0.   ],\n",
       "        [-44.669,   0.   ,   0.   ,   0.   ],\n",
       "        [-35.634,   0.   ,   0.   ,   0.   ],\n",
       "        [-26.112,   0.   ,   0.   ,   0.   ],\n",
       "        [ 21.493,   0.   ,   0.   ,   0.   ],\n",
       "        [ 15.414,   0.   ,   0.   ,   0.   ],\n",
       "        [-19.722,   0.   ,   0.   ,   0.   ],\n",
       "        [  4.489,   0.   ,   0.   ,   0.   ]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-88.459,  36.053,   5.965, -17.703],\n",
       "       [ 28.399, -12.488,  33.972,  60.124],\n",
       "       [ 89.814,  75.709,  95.046, -50.897],\n",
       "       [-45.428, -80.059, -22.983,  34.926],\n",
       "       [ 82.096,  58.668,  44.3  ,   2.159],\n",
       "       [ 16.587,   7.113, -69.58 , -25.374],\n",
       "       [ 24.689,  33.067,  25.018,  41.266],\n",
       "       [ 58.459,  21.332,  44.759,   9.113],\n",
       "       [ 89.187, -76.12 , -83.901,  57.824],\n",
       "       [-43.279, -76.765,  65.722,  30.286],\n",
       "       [-41.012,  81.   , -62.838,  63.346],\n",
       "       [-88.171, -24.372,  47.13 ,  -7.104],\n",
       "       [ 14.746,   8.844,   9.757, -97.087],\n",
       "       [-92.248,  -1.37 , -71.026,  12.074],\n",
       "       [ -5.267,  49.927, -31.957, -21.84 ],\n",
       "       [-30.399,  57.653,  43.136,  48.302],\n",
       "       [-31.95 ,  95.744,   4.232,  23.428],\n",
       "       [ 49.486,  23.054,  31.646,  26.824],\n",
       "       [-80.268, -57.051, -39.364, -12.898],\n",
       "       [ 31.15 ,  97.644, -21.4  , -66.403],\n",
       "       [ 13.399,  -7.78 ,  98.059,   0.979],\n",
       "       [ 52.645,  50.21 ,  10.111,   5.577],\n",
       "       [ 45.147, -79.036,  92.128, -35.128],\n",
       "       [-99.113,  33.126,  74.879, -27.683],\n",
       "       [-42.57 , -14.448,  23.426,  54.368],\n",
       "       [ 59.251, -60.299, -29.361,  70.296],\n",
       "       [-59.778,  41.824,  83.196, -82.774],\n",
       "       [-70.477, -45.033, -64.363, -68.167],\n",
       "       [-90.1  , -20.073,  20.922, -87.608],\n",
       "       [ 92.068, -99.9  , -19.668,  -2.316],\n",
       "       [-31.602, -53.195, -85.114, -34.778],\n",
       "       [ 16.543,  11.28 , -72.407,  -1.644],\n",
       "       [-44.498,  74.031, -52.413,   1.226],\n",
       "       [-47.095,  11.13 ,  70.887,  -1.023],\n",
       "       [ -0.626,  85.621,  13.579, -89.363],\n",
       "       [ 27.946,  73.973, -98.947, -78.118],\n",
       "       [ 92.827,  69.331, -64.776,  -0.65 ],\n",
       "       [ 87.169,  67.933,  14.876, -27.947],\n",
       "       [-62.883,  58.055, -19.137, -60.104],\n",
       "       [-83.767,  -4.917, -23.606,  35.206],\n",
       "       [ 80.797,  52.946,  44.2  , -39.139],\n",
       "       [-98.938, -13.766, -20.815,  37.229],\n",
       "       [-62.973, -82.526,  22.433, -56.952],\n",
       "       [ 92.511, -37.353,  64.56 ,  67.482],\n",
       "       [-37.038,  57.71 ,  82.539,  -7.514],\n",
       "       [ -1.472, -42.79 , -76.073, -65.019],\n",
       "       [-85.065, -30.259,  80.569,  94.634],\n",
       "       [-71.064,  26.868,  74.57 ,  16.131],\n",
       "       [-79.106,  33.633,  47.771, -95.953],\n",
       "       [ 22.146, -68.582, -66.283, -27.175],\n",
       "       [-51.   ,  60.119, -51.784, -95.688],\n",
       "       [ 98.176,   7.544, -46.107, -51.652],\n",
       "       [-76.627, -79.268,  -9.698,  61.013],\n",
       "       [ 23.396,  25.317,  16.762, -41.746],\n",
       "       [-66.354,   2.755, -60.473,  49.386],\n",
       "       [-99.243, -55.613,  33.274,  12.125],\n",
       "       [-65.247, -83.585, -98.401, -15.606],\n",
       "       [ 53.366,  91.751,  -7.672, -23.192],\n",
       "       [ 31.062, -65.253, -79.82 ,  13.183],\n",
       "       [ -0.777, -86.824,  13.177,  40.649],\n",
       "       [ 62.865, -38.918,  54.73 ,  77.436],\n",
       "       [ 20.053, -95.702, -14.309,  40.145],\n",
       "       [-95.3  ,  50.028, -60.928,  96.774],\n",
       "       [-78.279, -95.02 ,  14.463,  86.357],\n",
       "       [-97.006,  32.317,  12.931, -15.655],\n",
       "       [ 17.571,  41.893,  41.439,  93.98 ],\n",
       "       [ -0.152, -25.458, -25.94 ,  40.096],\n",
       "       [ 19.346, -59.181, -67.817,  35.926],\n",
       "       [ -6.096,  -2.484, -91.269,  68.817],\n",
       "       [-22.968,   3.216, -42.614,  -9.992],\n",
       "       [ 66.985, -96.064,  35.298,  44.486],\n",
       "       [-62.984, -16.054,   0.039,   2.919],\n",
       "       [  9.643, -66.29 , -25.699, -40.573],\n",
       "       [-55.303,  68.422,  78.731,  97.87 ],\n",
       "       [ 84.331,   6.76 ,  70.219, -96.848],\n",
       "       [-44.195, -40.094,  18.516,  87.074],\n",
       "       [ 32.125, -42.233,  12.409,  30.196],\n",
       "       [-23.33 , -81.133,   9.911,  48.509],\n",
       "       [ 82.617,  31.227, -56.884,  64.336],\n",
       "       [-44.567, -59.234, -11.853,  92.659],\n",
       "       [ 47.983,  88.569, -86.026, -81.955],\n",
       "       [ -9.722, -46.074, -98.091, -92.867],\n",
       "       [ 32.865,  49.434,  26.009, -24.9  ],\n",
       "       [ 38.066, -15.879,  -4.765, -70.622],\n",
       "       [ 35.21 ,  63.652,  10.954, -35.992],\n",
       "       [ 47.986,   8.027,  72.941,  82.895],\n",
       "       [-39.248, -37.831, -33.987,  90.903],\n",
       "       [-37.992, -23.406,  -3.337,  87.21 ],\n",
       "       [ 89.356, -44.735,  62.847,  55.951],\n",
       "       [-43.506, -19.445,  94.582, -66.258],\n",
       "       [-44.732, -50.849, -83.023,  -0.082],\n",
       "       [-25.16 ,  52.082,  62.393, -41.932],\n",
       "       [ 55.638, -62.164, -68.834,  31.856],\n",
       "       [-80.495, -31.706, -91.617,  25.143],\n",
       "       [-79.885,  14.401,  11.083, -88.135],\n",
       "       [-93.825, -97.24 ,  58.446,  28.172],\n",
       "       [  0.74 ,  97.468,  31.91 , -44.147],\n",
       "       [ 45.899, -55.542, -24.982,  96.281],\n",
       "       [-19.647, -70.876,  -2.467,  14.101],\n",
       "       [ 62.187, -58.337, -40.127,  54.234]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0:100,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(res[\"softmaxes_traind_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
