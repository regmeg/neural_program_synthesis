{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data_gen import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "batch_size = 5\n",
    "state_size = 4\n",
    "datatype = tf.float64\n",
    "num_of_operations = 3\n",
    "\n",
    "\n",
    "gloabal_seed = round(random.random()*100000)\n",
    "np.random.seed(gloabal_seed)\n",
    "tf.set_random_seed(gloabal_seed)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x,y = samples_generator(np_add, (batch_size, num_features) , (-1,1), gloabal_seed)\n",
    "\n",
    "batchX = tf.Variable(x, dtype=datatype)\n",
    "state  = tf.Variable(np.zeros([batch_size, state_size]), dtype=datatype)\n",
    "W      = tf.Variable(np.random.rand(state_size+num_features, state_size), dtype=datatype)\n",
    "W2     = tf.Variable(np.random.rand(state_size, num_of_operations),dtype=datatype)\n",
    "\n",
    "batchX.initializer.run()\n",
    "state.initializer.run()\n",
    "W.initializer.run()\n",
    "W2.initializer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_pass(batchX, state):\n",
    "    X_and_state_con = tf.concat([batchX, state], 1)\n",
    "    print(\"X_and_state_con\")\n",
    "    print(X_and_state_con.eval())\n",
    "    layer1          = tf.matmul(X_and_state_con, W)\n",
    "    print(\"layer1\")\n",
    "    print(layer1.eval())\n",
    "    #next_state      = tf.nn.sigmoid(layer1)\n",
    "    next_state      = tf.nn.relu(layer1)\n",
    "    print(\"next_state\")\n",
    "    print(next_state.eval())\n",
    "    state_dropped = tf.layers.dropout(next_state, 0.15, training = True)\n",
    "    print(\"state_dropped\")\n",
    "    print(state_dropped.eval())\n",
    "    logits = tf.matmul(state_dropped, W2)\n",
    "    print(\"logits\")\n",
    "    print(logits.eval())\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    print(\"softmax\")\n",
    "    print(softmax.eval())\n",
    "    softmax_l2_losts = tf.nn.l2_loss(100*softmax)\n",
    "    print(\"softmax_l2_losts\")\n",
    "    print(softmax_l2_losts.eval())\n",
    "    return softmax, next_state , logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_state_con\n",
      "[[ 0.87534304  0.9449777   0.          0.          0.          0.        ]\n",
      " [ 0.20325639  0.74427945  0.          0.          0.          0.        ]\n",
      " [ 0.07102169  0.19365824  0.          0.          0.          0.        ]\n",
      " [-0.29769086  0.53162387  0.          0.          0.          0.        ]\n",
      " [ 0.73457978  0.39143027  0.          0.          0.          0.        ]]\n",
      "layer1\n",
      "[[ 1.32683006  1.41525156  0.85846429  1.48709665]\n",
      " [ 0.58915745  0.64187222  0.3836419   0.74724606]\n",
      " [ 0.17030111  0.18464868  0.11073263  0.21024663]\n",
      " [ 0.00555411  0.02778756  0.00758294  0.14749588]\n",
      " [ 0.8984097   0.94798763  0.57939643  0.94041818]]\n",
      "next_state\n",
      "[[ 1.32683006  1.41525156  0.85846429  1.48709665]\n",
      " [ 0.58915745  0.64187222  0.3836419   0.74724606]\n",
      " [ 0.17030111  0.18464868  0.11073263  0.21024663]\n",
      " [ 0.00555411  0.02778756  0.00758294  0.14749588]\n",
      " [ 0.8984097   0.94798763  0.57939643  0.94041818]]\n",
      "state_dropped\n",
      "[[ 0.          0.          1.00995799  1.74952547]\n",
      " [ 0.          0.          0.45134341  0.87911301]\n",
      " [ 0.20035425  0.21723375  0.13027368  0.24734898]\n",
      " [ 0.00653424  0.03269125  0.0089211   0.17352457]\n",
      " [ 1.05695259  1.11527957  0.68164286  1.10637433]]\n",
      "logits\n",
      "[[ 5.29625856  3.3160399   1.49745475]\n",
      " [ 1.87752756  0.89180373  0.60842445]\n",
      " [ 0.70323748  0.43912468  0.19868723]\n",
      " [ 0.193174    0.11234968  0.05356125]\n",
      " [ 3.5056411   2.1989647   0.9916761 ]]\n",
      "softmax\n",
      "[[ 0.73036152  0.2198889   0.04974958]\n",
      " [ 0.63754961  0.2530828   0.10936759]\n",
      " [ 0.39001806  0.33439705  0.27558488]\n",
      " [ 0.35693561  0.33090163  0.31216276]\n",
      " [ 0.55053702  0.33953142  0.10993156]]\n",
      "softmax_l2_losts\n",
      "11926.0830312\n"
     ]
    }
   ],
   "source": [
    "state1 = run_pass(batchX, state)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_state_con\n",
      "[[ 0.87534304  0.9449777   1.32683006  1.41525156  0.85846429  1.48709665]\n",
      " [ 0.20325639  0.74427945  0.58915745  0.64187222  0.3836419   0.74724606]\n",
      " [ 0.07102169  0.19365824  0.17030111  0.18464868  0.11073263  0.21024663]\n",
      " [-0.29769086  0.53162387  0.00555411  0.02778756  0.00758294  0.14749588]\n",
      " [ 0.73457978  0.39143027  0.8984097   0.94798763  0.57939643  0.94041818]]\n",
      "layer1\n",
      "[[ 5.89864581  5.06631294  2.84040911  3.00865419]\n",
      " [ 2.71885603  2.35779467  1.30402808  1.47250741]\n",
      " [ 0.77931526  0.67438342  0.3741095   0.41660545]\n",
      " [ 0.18665614  0.19702299  0.0814331   0.23453769]\n",
      " [ 3.91777916  3.3476774   1.89052842  1.93269955]]\n",
      "next_state\n",
      "[[ 5.89864581  5.06631294  2.84040911  3.00865419]\n",
      " [ 2.71885603  2.35779467  1.30402808  1.47250741]\n",
      " [ 0.77931526  0.67438342  0.3741095   0.41660545]\n",
      " [ 0.18665614  0.19702299  0.0814331   0.23453769]\n",
      " [ 3.91777916  3.3476774   1.89052842  1.93269955]]\n",
      "state_dropped\n",
      "[[ 0.          5.96036816  3.34165777  3.53959316]\n",
      " [ 3.19865415  0.          1.53415068  1.73236166]\n",
      " [ 0.          0.79339226  0.44012882  0.49012406]\n",
      " [ 0.21959545  0.23179175  0.          0.27592669]\n",
      " [ 4.60915195  3.938444    0.          2.27376417]]\n",
      "logits\n",
      "[[ 14.5013113    9.18391019   3.80103955]\n",
      " [  5.07881128   4.35032136   1.76214994]\n",
      " [  2.35244774   1.43211393   0.62363884]\n",
      " [  0.72674579   0.44021855   0.18708818]\n",
      " [  7.08919181   6.13222963   2.48625889]]\n",
      "softmax\n",
      "[[  9.99261717e-01   6.21317339e-04   1.16965884e-04]\n",
      " [  9.59409978e-01   3.83260401e-02   2.26398169e-03]\n",
      " [  6.34565386e-01   2.52801987e-01   1.12632627e-01]\n",
      " [  4.28483081e-01   3.21733645e-01   2.49783275e-01]\n",
      " [  9.89325224e-01   1.04814531e-02   1.93322465e-04]]\n",
      "softmax_l2_losts\n",
      "1.61556432438\n"
     ]
    }
   ],
   "source": [
    "state2 = run_pass(batchX, state1)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_state_con\n",
      "[[-0.48194403 -0.6537931  -0.85560739 -0.70845758 -0.86175901 -0.91634596]\n",
      " [-0.31554519 -0.75737679 -0.86886513 -0.70403074 -0.86303768 -0.92530353]\n",
      " [ 0.25901108 -0.95455789 -0.85810936 -0.61887913 -0.80724577 -0.91586173]\n",
      " [ 0.30868902  0.13641044  0.3868672   0.31912044  0.42924907  0.46767314]\n",
      " [ 0.09877885 -0.03163367  0.01164019  0.03119781  0.0376305   0.01620849]]\n",
      "layer1\n",
      "[[-1.99743607 -1.53417104 -2.29186818 -3.11256198]\n",
      " [-2.0325854  -1.51650061 -2.30475129 -3.16475529]\n",
      " [-1.96562431 -1.35525399 -2.11392561 -3.07129776]\n",
      " [ 0.87549632  0.75034824  1.00605854  1.4037482 ]\n",
      " [ 0.04003409  0.06159064  0.07654249  0.07183651]]\n",
      "next_state\n",
      "[[-0.96384599 -0.91113567 -0.97977334 -0.99604966]\n",
      " [-0.96625888 -0.90808588 -0.98028278 -0.99644053]\n",
      " [-0.96151669 -0.87528771 -0.97125187 -0.99571054]\n",
      " [ 0.70415592  0.63535666  0.76412687  0.88615915]\n",
      " [ 0.04001272  0.06151288  0.07639336  0.0717132 ]]\n",
      "logits\n",
      "[[-2.94695597 -2.35917369 -1.86398304]\n",
      " [-2.94626789 -2.36060327 -1.8654151 ]\n",
      " [-2.9089552  -2.34328078 -1.85257531]\n",
      " [ 2.32188518  1.89298624  1.4918713 ]\n",
      " [ 0.20264129  0.1552851   0.11383096]]\n",
      "softmax\n",
      "[[ 0.17380909  0.31285499  0.51333592]\n",
      " [ 0.17411362  0.31274016  0.51314623]\n",
      " [ 0.17741268  0.31235894  0.51022838]\n",
      " [ 0.47909494  0.31199895  0.20890611]\n",
      " [ 0.34858185  0.33245911  0.31895905]]\n"
     ]
    }
   ],
   "source": [
    "state3 = run_pass(batchX, state2)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
