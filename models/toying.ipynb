{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data_gen import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "batch_size = 5\n",
    "state_size = 4\n",
    "datatype = tf.float64\n",
    "num_of_operations = 3\n",
    "\n",
    "\n",
    "gloabal_seed = round(random.random()*100000)\n",
    "np.random.seed(gloabal_seed)\n",
    "tf.set_random_seed(gloabal_seed)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x,y = samples_generator(np_add, (batch_size, num_features) , (-1,1), gloabal_seed)\n",
    "\n",
    "batchX = tf.Variable(x, dtype=datatype)\n",
    "state  = tf.Variable(np.zeros([batch_size, state_size]), dtype=datatype)\n",
    "W      = tf.Variable(np.random.rand(state_size+num_features, state_size), dtype=datatype)\n",
    "W2     = tf.Variable(np.random.rand(state_size, num_of_operations),dtype=datatype)\n",
    "\n",
    "batchX.initializer.run()\n",
    "state.initializer.run()\n",
    "W.initializer.run()\n",
    "W2.initializer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_pass(batchX, state):\n",
    "    X_and_state_con = tf.concat([batchX, state], 1)\n",
    "    print(\"X_and_state_con\")\n",
    "    print(X_and_state_con.eval())\n",
    "    layer1          = tf.matmul(X_and_state_con, W)\n",
    "    print(\"layer1\")\n",
    "    print(layer1.eval())\n",
    "    #next_state      = tf.nn.sigmoid(layer1)\n",
    "    next_state      = tf.tanh(layer1)\n",
    "    print(\"next_state\")\n",
    "    print(next_state.eval())\n",
    "    state_dropped = tf.layers.dropout(next_state, 0.15, training = True)\n",
    "    print(\"state_dropped\")\n",
    "    print(state_dropped.eval())\n",
    "    logits = tf.matmul(state_dropped, W2)\n",
    "    print(\"logits\")\n",
    "    print(logits.eval())\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    print(\"softmax\")\n",
    "    print(softmax.eval())\n",
    "    return softmax, next_state , logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_state_con\n",
      "[[ 0.87534304  0.9449777   0.          0.          0.          0.        ]\n",
      " [ 0.20325639  0.74427945  0.          0.          0.          0.        ]\n",
      " [ 0.07102169  0.19365824  0.          0.          0.          0.        ]\n",
      " [-0.29769086  0.53162387  0.          0.          0.          0.        ]\n",
      " [ 0.73457978  0.39143027  0.          0.          0.          0.        ]]\n",
      "layer1\n",
      "[[ 1.32683006  1.41525156  0.85846429  1.48709665]\n",
      " [ 0.58915745  0.64187222  0.3836419   0.74724606]\n",
      " [ 0.17030111  0.18464868  0.11073263  0.21024663]\n",
      " [ 0.00555411  0.02778756  0.00758294  0.14749588]\n",
      " [ 0.8984097   0.94798763  0.57939643  0.94041818]]\n",
      "next_state\n",
      "[[ 0.86847244  0.88860414  0.69546559  0.90278911]\n",
      " [ 0.52928936  0.56617298  0.36586607  0.63350312]\n",
      " [ 0.1686736   0.18257837  0.11028225  0.20720256]\n",
      " [ 0.00555405  0.02778041  0.00758279  0.14643551]\n",
      " [ 0.71552264  0.73887065  0.52222661  0.73541433]]\n",
      "state_dropped\n",
      "[[ 1.02173229  1.04541664  0.81819481  1.06210484]\n",
      " [ 0.62269337  0.66608586  0.          0.74529778]\n",
      " [ 0.19843953  0.21479809  0.12974382  0.24376771]\n",
      " [ 0.00653417  0.03268284  0.          0.17227708]\n",
      " [ 0.84179134  0.86925959  0.61438424  0.86519333]]\n",
      "logits\n",
      "[[ 3.50450241  2.22295331  1.05872989]\n",
      " [ 2.18157132  1.36737682  0.62760581]\n",
      " [ 0.69582613  0.43466509  0.19691977]\n",
      " [ 0.1920645   0.1117956   0.05325045]\n",
      " [ 2.82946569  1.78579882  0.83111678]]\n",
      "softmax\n",
      "[[ 0.73299484  0.20348444  0.06352072]\n",
      " [ 0.51096126  0.3155429   0.17349584]\n",
      " [ 0.42063621  0.32395587  0.25540793]\n",
      " [ 0.33696569  0.33579466  0.32723964]\n",
      " [ 0.67216954  0.23671189  0.09111858]]\n"
     ]
    }
   ],
   "source": [
    "state1 = run_pass(batchX, state)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_state_con\n",
      "[[ 0.87534304  0.9449777   0.86847244  0.88860414  0.69546559  0.90278911]\n",
      " [ 0.20325639  0.74427945  0.52928936  0.56617298  0.36586607  0.63350312]\n",
      " [ 0.07102169  0.19365824  0.1686736   0.18257837  0.11028225  0.20720256]\n",
      " [-0.29769086  0.53162387  0.00555405  0.02778041  0.00758279  0.14643551]\n",
      " [ 0.73457978  0.39143027  0.71552264  0.73887065  0.52222661  0.73541433]]\n",
      "layer1\n",
      "[[ 4.33090215  3.79366251  2.22132578  2.4408988 ]\n",
      " [ 2.47411516  2.15288106  1.20906387  1.37686881]\n",
      " [ 0.77272682  0.6688732   0.37156966  0.4140294 ]\n",
      " [ 0.18560087  0.19596798  0.08100298  0.23396901]\n",
      " [ 3.32766188  2.8729417   1.66121931  1.72169202]]\n",
      "next_state\n",
      "[[ 0.99965392  0.99898684  0.97674419  0.98494741]\n",
      " [ 0.98590808  0.97337795  0.83639846  0.88024818]\n",
      " [ 0.64851225  0.58423819  0.35536392  0.39188864]\n",
      " [ 0.18349866  0.19349731  0.08082627  0.2297912 ]\n",
      " [ 0.99742901  0.99362854  0.93038123  0.93806645]]\n",
      "state_dropped\n",
      "[[ 1.17606343  1.17527864  1.14911082  1.15876166]\n",
      " [ 1.15989186  1.14515053  0.98399819  1.03558609]\n",
      " [ 0.76295559  0.68733905  0.41807519  0.46104545]\n",
      " [ 0.21588078  0.          0.09508973  0.27034259]\n",
      " [ 0.          1.16897476  1.09456616  1.10360759]]\n",
      "logits\n",
      "[[ 2.98901304  2.43136867  1.18313396]\n",
      " [ 3.84706224  2.45805346  1.19152477]\n",
      " [ 2.07335494  1.27981235  0.56961546]\n",
      " [ 0.62635425  0.35632175  0.1211973 ]\n",
      " [ 3.02869063  1.71837418  0.56018991]]\n",
      "softmax\n",
      "[[ 0.77565705  0.17767073  0.04667222]\n",
      " [ 0.65304379  0.25832503  0.08863118]\n",
      " [ 0.59717993  0.27006856  0.1327515 ]\n",
      " [ 0.42674647  0.32207721  0.25117632]\n",
      " [ 0.76906966  0.18200412  0.04892621]]\n"
     ]
    }
   ],
   "source": [
    "state2 = run_pass(batchX, state1)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_and_state_con\n",
      "[[-0.48194403 -0.6537931  -0.85560739 -0.70845758 -0.86175901 -0.91634596]\n",
      " [-0.31554519 -0.75737679 -0.86886513 -0.70403074 -0.86303768 -0.92530353]\n",
      " [ 0.25901108 -0.95455789 -0.85810936 -0.61887913 -0.80724577 -0.91586173]\n",
      " [ 0.30868902  0.13641044  0.3868672   0.31912044  0.42924907  0.46767314]\n",
      " [ 0.09877885 -0.03163367  0.01164019  0.03119781  0.0376305   0.01620849]]\n",
      "layer1\n",
      "[[-1.99743607 -1.53417104 -2.29186818 -3.11256198]\n",
      " [-2.0325854  -1.51650061 -2.30475129 -3.16475529]\n",
      " [-1.96562431 -1.35525399 -2.11392561 -3.07129776]\n",
      " [ 0.87549632  0.75034824  1.00605854  1.4037482 ]\n",
      " [ 0.04003409  0.06159064  0.07654249  0.07183651]]\n",
      "next_state\n",
      "[[-0.96384599 -0.91113567 -0.97977334 -0.99604966]\n",
      " [-0.96625888 -0.90808588 -0.98028278 -0.99644053]\n",
      " [-0.96151669 -0.87528771 -0.97125187 -0.99571054]\n",
      " [ 0.70415592  0.63535666  0.76412687  0.88615915]\n",
      " [ 0.04001272  0.06151288  0.07639336  0.0717132 ]]\n",
      "logits\n",
      "[[-2.94695597 -2.35917369 -1.86398304]\n",
      " [-2.94626789 -2.36060327 -1.8654151 ]\n",
      " [-2.9089552  -2.34328078 -1.85257531]\n",
      " [ 2.32188518  1.89298624  1.4918713 ]\n",
      " [ 0.20264129  0.1552851   0.11383096]]\n",
      "softmax\n",
      "[[ 0.17380909  0.31285499  0.51333592]\n",
      " [ 0.17411362  0.31274016  0.51314623]\n",
      " [ 0.17741268  0.31235894  0.51022838]\n",
      " [ 0.47909494  0.31199895  0.20890611]\n",
      " [ 0.34858185  0.33245911  0.31895905]]\n"
     ]
    }
   ],
   "source": [
    "state3 = run_pass(batchX, state2)[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
